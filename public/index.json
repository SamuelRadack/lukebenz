[{"authors":["admin"],"categories":null,"content":"My name is Luke Benz and I am a first year Biostatistics PhD Student at the Harvard T.H. Chan School of Public Health. I graduated from Yale University in 2019 with a BS in Applied Mathematics with a concentration in Statistics and Data Science. While I do not yet know what my research at Harvard will entail, I have several diverse interests, including clinical trials, social networks, electronic health record (EHR) data, and cancer.\nBefore coming to Harvard, I was a senior data scientist at Medidata Solutions, Inc., where I most recently worked on models to select sites to use in clinical trials, and to forecast enrollment patterns and key milestones in those trials.\nIn my free time, I enjoy working on projects at the intersection of statistics and sports, and was president of the Yale Undergraduate Sports Analytics Group between 2017-2019. Many of my past projects have involved college basketball, and my R package ncaahoopR is designed to facilitate easy access and analysis of college basketball play-by-play data. My most recent publication related to sports examines the change in home advantage in European soccer during the COVID-19 pandemic, when games were played without fans.\n","date":1626307200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1626307200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://lukebenz.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"My name is Luke Benz and I am a first year Biostatistics PhD Student at the Harvard T.H. Chan School of Public Health. I graduated from Yale University in 2019 with a BS in Applied Mathematics with a concentration in Statistics and Data Science. While I do not yet know what my research at Harvard will entail, I have several diverse interests, including clinical trials, social networks, electronic health record (EHR) data, and cancer.","tags":null,"title":"Luke Benz","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://lukebenz.com/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://lukebenz.com/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://lukebenz.com/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://lukebenz.com/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Luke Benz","Michael Lopez"],"categories":null,"content":"","date":1626307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626307200,"objectID":"626d070cdd4242d64439776b46754a9a","permalink":"https://lukebenz.com/publication/soccer_covid_ha/","publishdate":"2021-07-15T00:00:00Z","relpermalink":"/publication/soccer_covid_ha/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Estimating the change in soccer's home advantage during the Covid-19 pandemic using bivariate Poisson regression","type":"publication"},{"authors":null,"categories":null,"content":" Introduction With the majority of sports on hiatus around the world, I’ve been eagerly following the German Bundesliga (the top flight of Germany soccer) the past two weeks to get my sports fix. Due to the ongoing COVID-19 outbreak, all games are currently being played without fans. A lot of prior research has shown the existence of home field advantage in soccer, which is believed to be the product of fans, referees, traveling, field composition, and other perhaps unobservable factors. With no fans in the stands, there is a nice opportunity for a natural experiment: How much home field advantage is there without fans? A nice literature review on the topic of home field advantage (HFA) in soccer and how it might waiver in the absence of fans is available courtsey of Singleton et. al.\n Analyzing Expected Outcomes One quick and dirty way to analyze the strength of HFA in the absence of fans is to compare the results of the first two weeks (18 games) since the Bundesliga’s return to what we’d expect given full HFA. To do this, I’ll use FiveThirtyEight’s pubically available SPI model. FiveThirtyEight predicts the win probability for both the home and away teams as well as the probabiligty of a draw. Using these probabilities, we can simulate the first two weeks of matches 10,000 times, and look at home many points (3 for win, 1 for draw) we’d expect to get accrued by home teams. This approach allows for the adjustment of team quality, as in a small sample, there could be more/less higher quality home teams. Note that FiveThirtyEight’s post-COVID return projections already reduce HFA by 10%.\nClearly the results are pretty unexpected even assuming a 10% HFA reduction. This isn’t to suggest that HFA is completely gone without fans, but it does suggest that it probably is reduced by more than 10%. I’ll note that a March 11 game between behind closed doors between Borussia Monchengladbach and FC Cologne, but I’m not including that here since a) it was before a long lay off and b) it was before FiveThirtyEight reduced it’s HFA.\n How Much is HFA Reduced So if 10% isn’t enough, how much should HFA be reduced? To answer this question I’ll need to recreate a model very similar to FiveThirtyEight’s model so that I can manually adjust HFA. More on the methodology between FiveThirtyEight’s model can be found here, but as a simplified summary:\n\\[ Y_1 \\sim \\text{Poisson}(\\lambda_1)\\\\ Y_2 \\sim \\text{Poisson}(\\lambda_2) \\] where \\(Y_i\\) is the number of goals scored by team \\(i\\). Using FiveThirtyEight’s publically available data, I fit a possion regression model using b-splines on each of the team’s Soccer Power Index (SPI) plus a home team indicator.\nWe can see that my simplified model is a pretty good approximation of FiveThirtyEight’s model. Perhps it slightly underestimates certain draw probabilities, as FiveThirtyEight inflates draw probabilities from their Poisson model, but it’s a useful enough approximation for the purposes I’d like to use it for. Now, we can manually control the reduction in HFA and see where our observed results compare to expected results.  Discussion What’s really tricky about analyzing the effect of HFA in the absence of fans is that these results seem very unlikely even in the complete removal of home field avantage, so it’s hard to say what is a realistic estimate for just how much HFA should be reduced. I think one thing to note is that because I am since I am not recreating FiveThirtyEight’s draw probability inflation, the medians of these red distribution should probably be slightly left of where they are (if we are to believe their model). As more games come in over the coming weeks, we should have a better sense of where HFA stands. A more rigorous analysis of this problem would likely utilize a Bayesian framework and use Pre-COVID results to set priors. As Laurie Shaw rightly points out, the layoff between games has likely increased uncertainty in FiveThirtyEight’s SPI ratings, which should be accounted for in a more rigorous examination. Stay tuned for more analysis are more games, both in Germany and other countries, are played without fans.\nCode for this post can be found (and will be updated) here.\n ","date":1590364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590364800,"objectID":"d23591641576df9aa08e3f47288c7ecb","permalink":"https://lukebenz.com/post/bundesliga_hfa/","publishdate":"2020-05-25T00:00:00Z","relpermalink":"/post/bundesliga_hfa/","section":"post","summary":"Introduction With the majority of sports on hiatus around the world, I’ve been eagerly following the German Bundesliga (the top flight of Germany soccer) the past two weeks to get my sports fix. Due to the ongoing COVID-19 outbreak, all games are currently being played without fans. A lot of prior research has shown the existence of home field advantage in soccer, which is believed to be the product of fans, referees, traveling, field composition, and other perhaps unobservable factors.","tags":["Soccer"],"title":"Bundesliga Home Field Avantage in the Absence of Fans","type":"post"},{"authors":null,"categories":null,"content":" Introduction While Australian Rules Football (AFL) recently suspended its season, it was for a brief moment in time, the most popular sports league in the world (if only due to the fact the every other major sports league had already shut down). AFL is actually really fun to watch, and I’d highly recommend checking it out once its season returns. One of the parts of AFL that has always interested me is its unique playoff structure–an eight team playoff that is a hybrid of single elimination (for seeds 5-8) and “psuedo” double elimination (for seeds 1:4).\nThis tournament structure is super interesting in the context of college basketball conference tournaments. Every win a team earns in the NCAA tournament nets its conference about 1.7 million dollars split equally amongst each member school. Hence, conferences (particularly those mid-major conferences which only send one representive to the big dance) have big incentives to send their best team to the NCAA tournament.\nDoes the AFL playoff structure better protect top seeds compared to the two most common tournament formats currently used by conferences (neutral site tournament and higher seed home court advantage). On one hand, the top seed(s) have the advantage of a mulligan in the case of a first round slip up, but simultaneously have a more difficult first round (and possibly semi-final) matchup. The answer to this question is somewhat dependent on the distribution of team stength across the tournament. To examine this question, I ran the following simulation.\nTake the top 8 teams in each of the 32 conferences by record (ties broken using my ranking system found here). Simulate 8 team, single elimination tournament where the home court advantage is given to the higher seed in each matchup. Repeat 1000 times for each conference. Simulate 8 team, single elimination tournament where the the entire tournament is hosted at a neutral site. Repeat 1000 times for each conference. Simulate 8 team, AFL style tournament. Repeat 1000 times for each conference.  Of course, most conference tournaments have more than 8 participants, but those that do usually eventually result in 8 remaining teams (usually at a neutral site), and 8 teams is the easiest way to compare formats with the 8 team AFL style.\n Simulation Results First, we must start by comparing the standard single elimination 8 team formats. It’s little suprise to see that giving the better seed in each matchup home court advatage is beneficial to these higher seeds. Every single conference’s top seed is more likely to win the tournament with the option to host as long as they keeping, and similarly for the top 2 seeds chance’s of reaching the finals. Given that the majority of conference play neutral site conference tournaments, we are perhaps most interested in comparing that tournament format to the unique AFL tournament style. Clearly, the AFL tournament provides some benefit to the top seeds in the tournament. Some of the may be driven by hosting games, but likely the majority of it is driven by first round mulligan alloted to the top-4 seeds. Compare the differences between the 4- and 5- seed in these 2 tournament formats. The 4- seed does not host its first round game while the 5- seed does, but the 4- seed seems an improvement in its odds of reaching/winning the finals because it survives a first round loss.\nFinally, we compare the simulated probabilities of winning/reaching a tournament final between the higher seed always getting home court and the AFL style. While there isn’t a huge difference in the chances of the top 2 seeds reaching the finals between the two scenarios, the 3- and 4- seeds are much likelier to reach the finals in the AFL style tournament. Across the board, however, the top seed is less likely to win the AFL style tournament. This is because in the AFL style tournament, the final is played at a neutral site compared to the higher seed getting to host the championship game.\nSo it seems that the home court advantage format makes it most likely for a conference to send its best team to the NCAA tournament (at least via automatic bid). But maybe this is not what’s best for the conference. Maybe instead, it would rather send the best team in expectation. That is, maybe it would rather maximize the chances that a top-4 team would make the tournament. We can quantify this in terms of the expected value of conference champion team strength.\nLet \\(\\gamma_i\\) denote the team strength of team \\(i\\). Specifically, \\(gamma_i\\) denotes the number of points team \\(i\\) would be expected to win/loss by against an average team on a neutral floor. If you’re interested in the math behind estimating \\(\\gamma_i\\), check out this post.\nLet \\(C\\) denote the team strength of the conference champion. We see that \\[ E(C) = \\sum_{i \\in \\text{conference}} \\gamma_i p_i \\] where \\(p_i\\) denotes the chances that team \\(i\\) wins its conference tournament. Now, we can compare \\(E(C)\\) for each conference under the 3 different types of tournament simulations.\nIn 8 of the 32 conferences, the AFL style tournament yields the highest expected champion \\(E(C)\\), while the higher seed HCA format yields the highest expected champion in the remaining 24 conferences.\n  conference exp_champ_H exp_champ_afl exp_champ_N    ACC 17.59 18.00 16.83  Big 10 17.81 18.09 16.91  Big Sky 4.16 4.71 3.50  MEAC -6.87 -6.75 -7.52  NEC -2.72 -2.30 -3.19  SEC 13.04 13.12 12.42  Summit 2.45 2.50 1.96  Sunbelt 3.60 3.83 3.19    What do these 8 conferences all have in common? We can compare standardized team strength (Z-score of \\(\\gamma_i\\) across conference) by seed, and see that all of these conferences have weaker top seeds with better concentration of talent across the top 3 or 4 seeds.\n Summary The AFL style tournament offers a unique style of top-seed protection from what currently exists. It is clearly superior to the neutral site single elimination format, and even is an improvement on the higher seed HCA format in some cases. Overall, the full extent of the advantages that this format provides is dependent on how talent is distributed across the conference. It probably doesn’t help much for conferences with one team far superior to the rest (New Mexico State in the WAC, Vermont in the America East for example), but it does help in conferences with talent pretty well distributed across the top 4 seeds in the conference (and possibly a weak top seed). I’d imagine that neutral site tournaments are a big source of revenue for these conferences, perhaps enough to offset the potential gains of winning money from NCAA tournament games. One potential solution is to run a neutral site version of this format.\nOf course, one difficulty is that you’d have to extend this format to accept more than 8 teams, otherwised you’d be eliminating many of the teams in each conference before postseason play had even begin. Finally, there is just something so nice about single elimination tournaments–it’s what makes March Madness crazy. The purpose of March Madness is not to crown the best team, so it seems like the adoption of this hybrid AFL format would be far-fetched. One can hope though, and in the mean time, I’d like to see more formats like the triple bye to top seeds in the WCC.\n ","date":1585094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585094400,"objectID":"26a974ea36cc12cb7bed6447ff1a15c6","permalink":"https://lukebenz.com/post/afl_tournament_sims/","publishdate":"2020-03-25T00:00:00Z","relpermalink":"/post/afl_tournament_sims/","section":"post","summary":"Introduction While Australian Rules Football (AFL) recently suspended its season, it was for a brief moment in time, the most popular sports league in the world (if only due to the fact the every other major sports league had already shut down). AFL is actually really fun to watch, and I’d highly recommend checking it out once its season returns. One of the parts of AFL that has always interested me is its unique playoff structure–an eight team playoff that is a hybrid of single elimination (for seeds 5-8) and “psuedo” double elimination (for seeds 1:4).","tags":["NCAA Basketball","AFL"],"title":"Could an AFL Style Tournament Structure be Utilized in College Basketball","type":"post"},{"authors":null,"categories":null,"content":" I’m excited to release ncaahoopR version 1.5 today. ncaahoopR started off as me putting together a few of my side projects into a single place. It was convenient for my work flow, and I wasn’t too sure other people would even use it. Fast forward a year and half, and the current number of people using the package far exceeds what I ever could have imagined. The uptick in users, particuarly during this current season, has made me really excited about the possibilities that lie ahead.\nncaahoopR is being used by managers and assistant coaches at Division 1 schools, by journalists, and by casual fans like myself. Version 1.5 of the package brings the biggest changes to the package since Verion 1.0 was released. The package has enough users around the web that beginning with this version, I will be doing better version control by keeping a developmental branch and releasing changelogs for big updates. So, let’s take a tour of what’s new in ncaahoopR version 1.5.\nPossession Parsing The biggest update to the package is that two new columns (possession_before and possession_after) demarcate which team has possession before and after each play. ESPN play-by-plays logs don’t automatically tag pre- and post-play possession, so using team rosters, I parse possessions applying the following set of assumptions:\nShooting teams have possesion on the play before they shoot. On made shots (non-free throws), the possession after the play switches to the other team. For missed shots, the correct rebound is the first possible rebound that is:   In the same half Before any future shot  All actions between a missed shot and rebound maintain the same before/after possession team Turnovers/Steals:   If steal, possesion go to stealing team from other team If turnover, possesion goes from turnover team to other team  Fouls: Foul gives possession to non-foul committing team Missed Free Throws are rebounded by the next unmapped rebound before next shot. Then proceed as assumption 4. Deadball Team Rebounds implies possesion after for the deadball rebounding team. All non-Free Throw sequences occuring at the same time not yet tagged get the same before possesion mapping as the first event at that time period and the same after possesion mapping as the last event at that time period. All Remaining sequences don’t involve change of possession.  While these assumptions have been carefully considered, they probably miss some corner cases. If you encounter any play-by-play logs where you think possession has been incorrectly parsed, please let me know by opening an issue on GitHub or commenting on Twitter.\n Shot Data ncaahoopR has always had shot data courtesy of Meyappan Subbaiah, but it has always been seperate from play-by-plays logs…until now! Now, the default behavior for the get_pbp_game() function is to include the following columns of shot-related data.\n shot_x: The half-court x coordinate of shot. shot_y: The half-court y coordinate of shot. shot_team: Name of team taking shot. shot_outcome: Whether the shot was made or missed. shooter: Name of player taking shot. assist: Name of player asssisting shot (assisted shots only) three_pt: Logical, if shot is 3-point field goal attempt. three_pt: Logical, if shot is free throw attempt.  For (shot_x, shot_y) pairs, (0,0) represents the bottom left corner and (50, 47) represents the top right corner (from persepective of standing under hoop). Note that shot locations are usually only avaialble for high-major teams, and are left as NA if not available.\nBoth the possession parsing and shot location linkage cause get_pbp_game() to take a few additional seconds per game. If you don’t need these variables and want to speed up the scraping, simply pass in extra_parse = FALSE to the function.\n Historical Coverage While ncaahoopR has always been able to scrape play-by-play data for any valid game_id a user provided, finding historical game_id values further back than the current season wasn’t possible in previous verions of the package. Now, all of the following functions accept an optional season argument to overide the default current season (in the form “YYYY-YY”).\n get_roster(team, season = current_season): Available through 2007-08 get_schedule(team, season = current_season): Available through 2002-03 get_game_ids(team, season = current_season): Available through 2002-03 get_pbp(team, season = current_season): Available through 2002-03  Additionally, the assist_net and circle_assist_net now go back through the 2007-08 season given the historical roster coverage. Unlike schedules, rosters from past seasons are not archived on ESPN. Historical coverage of rosters comes from Bart Torvik’s site.\n Naive Win Probability Right before version 1.5, I added the naive_win_prob, a version of win probability starting at 50-50 and not using any information about pre-game spread, to the play-by-play logs. Now users, have the option to select whether to use naive_win_prob instead of the default win_prob by setting include_spread = FALSE in the following functions:\n wp_chart gg_wp_chart game_excitement_index average_win_prob  library(ncaahoopR) library(patchwork) osu_color \u0026lt;- ncaa_colors$primary_color[ncaa_colors$ncaa_name == \u0026quot;Ohio St.\u0026quot;] uk_color \u0026lt;- ncaa_colors$primary_color[ncaa_colors$ncaa_name == \u0026quot;Kentucky\u0026quot;] ### Classic gg_wp_chart(401166125, home_col = uk_color, away_col = osu_color, include_spread = T, show_labels = F) ### Naive gg_wp_chart(401166125, home_col = uk_color, away_col = osu_color, include_spread = F, show_labels = F)  Smaller Changes There are several other small improvements to the package.\n get_master_schedule(date) now takes a single date argument, and is robust to future dates. play_length variable was fixed so it relfects the time (in seconds) from the previous play to the current play, rather than the current play to the next play (as the description usually represents the end of a play and not the beginning). Rows where the score differential changes w/out any shot being made are now removed. This fixes a bug in ESPN data from the current season where certain events are given incorrect times. Colors for remaining 105 schools and logos for all 353 schools added to ncaa_colors data frame courtsey of Luke Morris.   Data Repository In case you don’t like R or don’t know R, or don’t want to have to scrape thounsands of games worth of data, I’ve uploaded lots of historical data to the following GitHub repository.\n Over 50,000 Play-by-play logs dating back to 2002-03 Schedules back to 2002-03 Rosters back to 2007-08  Data includes possession and shot variables only as far back as 2017-18 due to increased scraping time.\n So What’s Coming in v1.6 While a lot as been added in the lastest version of the package, I think it is just the beginning of what is still to come. Here are some things I’d like to add to the package in 1.6, but I’d love to hear what features ncaahoopR users would like to see as well.\n Box Scores Once possesion parsing has undergone greater quality control checks, I hope to :  Re-train win probability models to include possesion (which is huge factor in end of game scenarios) Add win probability added (WPA) framework, stats, and graphics  Best guess at “time on shot clock”  Thanks for using ncaahoopR. Be sure to use #ncaahoopR if you share your work on Twitter so I can keep tabs on the package in the wild and promote your work within the community.\n ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"99b51ae5d7c12849eea4c51d337757c6","permalink":"https://lukebenz.com/post/ncaahoopr_v1.5/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/post/ncaahoopr_v1.5/","section":"post","summary":"I’m excited to release ncaahoopR version 1.5 today. ncaahoopR started off as me putting together a few of my side projects into a single place. It was convenient for my work flow, and I wasn’t too sure other people would even use it. Fast forward a year and half, and the current number of people using the package far exceeds what I ever could have imagined. The uptick in users, particuarly during this current season, has made me really excited about the possibilities that lie ahead.","tags":["ncaahoopR"],"title":"What's New in ncaahoopR Version 1.5","type":"post"},{"authors":null,"categories":null,"content":"","date":1576195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576195200,"objectID":"0131f88b9ef898b65cb2ac0889a85eb5","permalink":"https://lukebenz.com/project/ncaahoopr/","publishdate":"2019-12-13T00:00:00Z","relpermalink":"/project/ncaahoopr/","section":"project","summary":"An R package for working with NCAA Basketball Play-by-Play Data","tags":["NCAA Basketball","Software"],"title":"ncaahoopR","type":"project"},{"authors":null,"categories":null,"content":" A collection of links to various basketball related shiny apps\nRecspecs730 Basketball Central An R Shiny Application containing NCAA Basketball:\n Power Rankings Conference Simulations and Breakdowns Team Breakdowns Game Projections Bracketology  Application\nIvy League TiebreakR An R Shiny Application for determining playoff seed for Ivy Madness based on user-input game outcomes.\n Application  NCAA Assist Networks An R Shiny Application for NCAA Basketball Assist Networks\n Application  New York Section 2 Basketabll Assist Networks An R Shiny Application for rending high school basketball assist networks.\n Application Press Release  ","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"427fd65dcc2b53265ae0238a892a8efc","permalink":"https://lukebenz.com/project/shiny_apps/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/project/shiny_apps/","section":"project","summary":"A collection of links to various basketball related shiny apps.","tags":["NCAA Basketball","Software"],"title":"Basketball Shiny Apps","type":"project"},{"authors":null,"categories":null,"content":" As part of my thesis this past spring, I improved on the win probability built into my ncaahoopR package. The new win probability model has now been integrated into the package for the upcoming 2019-20 college basketball season. In this post, I provide some background on the statistical details of the model.\nWin Probability Model Framework Let \\(p_{ikt}\\) denote the probability that team \\(i\\) wins game \\(k\\) with time \\(t\\) remaining in the game. Let \\(Y_{ik}\\) be an indicator whether team \\(i\\) won the game \\(k\\). The following model is assumed: \\[ \\begin{aligned} Y_{ik} | p_{ikt} \u0026amp;\\sim \\text{Bernoulli}(p_{ikt}) \\\\ \\text{logit}(p_{ikt}) \u0026amp;= X_{ikt}^{\\scriptstyle T}\\beta_t + \\epsilon_{ikt} \\\\ \\epsilon_{ikt} \u0026amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] In the above model, observations are of the form $ X_{ikt}, Y_{ik})$, where $ X_{ikt}$ denotes a vector of covariates of interest with time \\(t\\) remaining in game \\(k\\) and, \\(Y_{ik}\\) is an indicator whether team \\(i\\) won \\((Y_{ik} = 1)\\) or lost \\((Y_{ik} = 0)\\) the game in question. \\(X_{ikt}\\) occur at discrete, non-regular time points \\(t\\), as observations are only available after the occurrence of certain game events (such as a made basket, foul, turnover, or timeout) which don’t adhere to a regular time schedule.\n\\(\\beta_t\\) represents the vector of coefficients for the covariates of interest with time \\(t\\) remaining. One challenge in fitting the above model is that the covariates of interest, such as score differential and pre-game point spread, have non-linear dependencies on the amount of time remaining in the game. While time remaining is not explicitly a covariate in any version of this model, coefficient estimates for covariates of interest are obtained at various values of time remaining \\(t\\). To combat covariates’ non-linear dependence on time, various versions of this type of college basketball win probability model, including work by Brian Burke and Bart Torvik have broken the game into discrete time chunks, over which the coefficients are assumed to be constant.\nHowever, numerous problems can arise when one categorizes or makes discrete a continuous variable. To get around this problem, I fit several versions of this model were over discrete time intervals which overlapped by 90%. LOESS smoothing was then applied to the resulting coefficient estimates to obtain smooth coefficient functions over time. Coefficient estimates represent the increase in the log odds of winning a game while holding all of the other covariates in the model constant.\nI trained and tested several variations of this kind of model, which you can read about here. The model ultimately settled on is as follows:\nFor each interval of the form \\((t - \\Delta, t]\\), a logistic regression fit with covariates Pre Game Point Spread (favored_by) and Score Differential (score_diff) such that \\(t - \\Delta \\leq\\) time_remaining \\(\\leq t\\). Consecutive intervals overlap one another by 90%. As the time remaining, \\(t\\) approaches \\(0\\), the rate at which model coefficients change with time increases. As such, \\(\\Delta\\) is decreased in order to properly capture the manner in which these coefficients vary as a function of time.\n    Variables Included Time Interval Structure \\((t - \\Delta, t]\\)     Score Differential Pre Game Point Spread   \\(\\Delta =\\) 100, \\(600 \\leq t \\leq 2400\\) \\(\\Delta =\\) 50, \\(100 \\leq t \\leq 600\\) \\(\\Delta =\\) 10, \\(10 \\leq t \\leq 100\\) \\(\\Delta =\\) 2, \\(1 \\leq t \\leq 10\\) \\(\\Delta =\\) 1, \\(0 \\leq t \\leq 1\\)     Essentially, this method is related to a Generalized Additive Model (GAM). In simple terms a GAM is a linear combination of some unknown smoothed functions over the covariates. What I have done is essentially reverse the steps–I fit linear combinations of predictors (with logit link function) and then smooth over the time dependent results. This was done to gain a little bit more interpretability of the coefficient values, although I think a GAM could be fit and obtain vary similar results.\nWe see in the coefficient trace plot below the obvious result that as the game progresses, the pregame line becomes less important in predicting win probability and the current score differential becomes increasingly more important  Model Calibration The model above was trained on 10,949 games from the 2016-17 and 2017-18 seasons and tested on 3,625 games from the first part of the 2018-19 season. Using the idea of calibration plots from Michael Lopez’s win probability post after the 2017 Super Bowl, I compare bins of predicted and observed probability over the course of the game. We see that the model is well calibrated for all situations.\n Summary Compared to the older win probability model, the new win probability model is smoother and a little bit more interpretable. It is trained on a larger sample of data and is better calibrated, especially in late game situations. I still think there are some improvements that can be made in the future, especially accounting for possession in the final few minutes of the game. Nevertheless, it’s nice to see something fairly simple performing so well, and to integrate something I worked on for my thesis into the package. Be on the lookout for new win probability charts dropping at the beginning of this season!\n ","date":1571184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571184000,"objectID":"d12e07e98f8a896c22ae2167f9aedbf3","permalink":"https://lukebenz.com/post/ncaahoopr_win_prob/","publishdate":"2019-10-16T00:00:00Z","relpermalink":"/post/ncaahoopr_win_prob/","section":"post","summary":"As part of my thesis this past spring, I improved on the win probability built into my ncaahoopR package. The new win probability model has now been integrated into the package for the upcoming 2019-20 college basketball season. In this post, I provide some background on the statistical details of the model.\nWin Probability Model Framework Let \\(p_{ikt}\\) denote the probability that team \\(i\\) wins game \\(k\\) with time \\(t\\) remaining in the game.","tags":["ncaahoopR"],"title":"A New ncaahoopR Win Probability Model","type":"post"},{"authors":["Elizabeth Claus","Josemari Feliciano","Luke Benz","Lisa Calvocoressi"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"dad986142eb0ce605207bcf10b8e6a19","permalink":"https://lukebenz.com/publication/social_media_recruitment/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/social_media_recruitment/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Social media partnerships with patient organizations for neuro-oncology patient recruitment","type":"publication"},{"authors":["Luke Benz"],"categories":null,"content":"","date":1569628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569628800,"objectID":"82b96a203bef757a27a5d2602252964c","permalink":"https://lukebenz.com/posters/nessis_2019/","publishdate":"2019-09-28T00:00:00Z","relpermalink":"/posters/nessis_2019/","section":"posters","summary":"Presented at _New England Symposium of Statistics in Sports_, Boston, MA","tags":null,"title":"An Examination of Timeout Value, Strategy, and Momentum in NCAA Division 1 Men's Basketball","type":"posters"},{"authors":null,"categories":null,"content":" An Examination of Timeout Value, Strategy, and Momentum in NCAA Division 1 Men\u0026rsquo;s Basketball Senior Thesis in Applied Mathematics, Spring 2019\n Paper Poster GitHub Repository This work won first place in the the 2019 Spring USPROC Reseach Contest.  A Bayesian Examination of Win Probability and Timeout Usage in NCAA Men\u0026rsquo;s Basketball Final Project for BIS 567, Fall 2018\n Poster  Weighting Schema for Regression Based Ratings and Predictions in Australian Rules Football Final Project for S\u0026amp;DS 312, Fall 2018\n Paper  ","date":1558483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558483200,"objectID":"e65359048fda49451cce3efa88efc2b3","permalink":"https://lukebenz.com/project/sports_research/","publishdate":"2019-05-22T00:00:00Z","relpermalink":"/project/sports_research/","section":"project","summary":"A collection of sports research projects","tags":["AFL","NCAA Basketball","Research"],"title":"Sports Analytics Research","type":"project"},{"authors":null,"categories":null,"content":" A collection of links to various sports analytics projects not already linked in projects/posts.\nNCAA Basketball  Do Deep NIT Runs Predict Future NCAA Success? (3/22/2018)\n The Value of Switching Conferences (12/20/2017)\n  MLB  Effect of Baserunners on MLB Pitch Selection (6/30/2017)\n What Makes a Cy Young? (5/19/2017)\n  NBA  CS50: What I Learned (1/19/2017)  Podcasts  Wharton Moneyball on my Hotdog Analytics (7/11/18)\n Union Street Hoops Podcast (12/28/17)\n On the Vine Ivy Hoops Podcast (2/16/17)\n  ","date":1558396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558396800,"objectID":"415af623d51dced18d4eae014877d7e2","permalink":"https://lukebenz.com/project/yusag/","publishdate":"2019-05-21T00:00:00Z","relpermalink":"/project/yusag/","section":"project","summary":"A list of sports analytics projects completed while in the Yale Undergraduate Sports Analytics Group","tags":null,"title":"Yale Sports Analytics","type":"project"},{"authors":null,"categories":null,"content":" NCAA Basketball  BY THE NUMBERS: Yale Just Falls to LSU (3/27/2019)\n BY THE NUMBERS: Most Exciting Ivy Games (2/27/2019)\n BY THE NUMBERS: Ivy Hoops Midseason Rankings (2/13/2019)\n BY THE NUMBERS: Ivy Hoops Power Rankings (1/30/2019)\n BY THE NUMBERS: Yale vs. Duke Preview (12/5/2018)\n BY THE NUMBERS: How Mad was March? (4/4/2018)\n BY THE NUMBERS: Yale Heads to Ivy Madness (3/7/2018)\n BY THE NUMBERS: Ivy Hoops Enters Home Stretch (2/20/2018)\n BY THE NUMBERS: Math to Ivy Madness (2/8/2018)\n BY THE NUMBERS: Ivy Basketball Analytics (1/23/2018)\n BY THE NUMBERS: Replacing Makai Mason (12/5/2017)\n BY THE NUMBERS: Ivy Math-ness (3/11/2017)\n BY THE NUMBERS: Yale\u0026rsquo;s Chances of Making the Ivy League Tournament (3/1/2017)\n BY THE NUMBERS: Basketball Begins (1/18/2017)\n  NCAA Baseball and Softball  BY THE NUMBERS: Baseball MVPs (4/17/2018)\n BY THE NUMBERS: Softball MVPs (4/10/2018)\n (2018 Ivy Baseball/Softball WAR Leaderboard)  BY THE NUMBERS: MVPs (4/26/2017)\n (2017 Ivy Baseball/Softball WAR Leaderboard)   NCAA Football  BY THE NUMBERS: A Statistical History of \u0026lsquo;The Game\u0026rsquo; (11/16/2018)\n BY THE NUMBERS: Princeton\u0026rsquo;s Success (11/7/2018)\n BY THE NUMBERS: Rise of Ivy League Football Recruiting (10/10/2018)\n BY THE NUMBERS: Ivy League Football Preview (9/11/2018)\n BY THE NUMBERS: Ivy Title Race Heats Up (11/1/2017)\n BY THE NUMBERS: Ivy Football Quick Hits (10/11/2017)\n BY THE NUMBERS: How to Win an Ivy League Football Championship (9/6/2017)\n  Other  BY THE NUMBERS: Ivy League Lacrosse (4/4/2017)  ","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"3d0117f8ad8b4aa6dd9fe7ef26b56ce0","permalink":"https://lukebenz.com/project/ydn_articles/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/project/ydn_articles/","section":"project","summary":"A complete list of my \"BY THE NUMBERS\" sports column in the Yale Daily News.","tags":["Data Journalism"],"title":"Yale Daily News","type":"project"},{"authors":null,"categories":null,"content":"  Below is my submission methodology for the 2019 American Statistical Association Statsketball Draft Challenge. Having won the contest in 2018, I knew that I had to up my game this year to defend my crown.\nContest Background The Statsketball Draft Challenge asks participants the chance to select NCAA Tournament Teams using a budget of 224 draft points. The cost of each team, in draft points, is based on the team’s seed.\n  seed  cost      1  75    2  40    3  25    4  20    5  17    6  15    7  12    8  10    9  9    10  8    11  7    12  6    13  5    14  4    15  3    16  1     The deeper each team goes in the tournanement, the more points they accrue, with each round more valuable than the last. Wins in each round are worth 1, 2, 3, 5, 8, and 13 points, respectively. The goal of the contest is to score the most points by selecting a subset a group of teams within the alloted budget.\n Methodology NCAA Hoops Model A key ingredient to my submission is the NCAA men’s basketball model that I have developed over the last 3 years. In very simple terms, the model using weighted least squares regression to predict score differentials between any two teams, and then utilizes logistic regression to transform the obtained pointspread into a win probability for each team. The specifics of this model are not the primary focus of the Statsketball tournament submission, but for those curious, a detailed write-up of the model methodology can be found here. For the purposes of this contest, all that is important is knowing is that given teams \\(A\\) and \\(B\\), the model outputs, \\(P_A\\) and \\(P_B\\), the chances that team \\(A\\) and team \\(B\\) win the game, respectively.\n Simulating the NCAA Tournament The second step in my submission invloved running Monte Carlo simulations of the NCAA tournament. A single simulation of the tournament used the following steps\nUse NCAA Hoops Model to predict the win probabilities for all 32 games in first round. Draw 32 random numbers from a uniform distribution, one for each game. Let game \\(i\\) be played between team \\(A_i\\) and team \\(B_i\\) If the \\(i^{th}\\) random number is \\(\\leq\\) team \\(A_i\\)’s chances of winning, advance team \\(A_i\\) to the next round. Otherwise, advance team \\(B_i\\) to the next round. Repeat step 3 for all games in given round. Repeat setps 1-4 for subsequent rounds, until a champion is crowned.  I ran 10,000 simulations of the NCAA tournament to obtain estimates of the probabilities of each team reaching each round. R code for running these simulations can be found here. The results of my simulations are shown below.\n  team  seed  region  r64  r32  s16  e8  f4  ncg  champ      Gonzaga  1  West  1.0000  0.9954  0.9133  0.7932  0.6129  0.4113  0.2653    Duke  1  East  1.0000  0.9928  0.9036  0.7341  0.5039  0.3367  0.1928    Virginia  1  South  1.0000  0.9866  0.8822  0.7261  0.5267  0.2890  0.1682    North Carolina  1  Midwest  1.0000  0.9889  0.8877  0.6631  0.4617  0.2354  0.1081    Michigan St.  2  East  1.0000  0.9824  0.7774  0.6230  0.3082  0.1867  0.0870    Kentucky  2  Midwest  1.0000  0.9695  0.7446  0.5019  0.2380  0.0954  0.0362    Michigan  2  West  1.0000  0.9549  0.7001  0.4205  0.1518  0.0688  0.0276    Tennessee  2  South  1.0000  0.9508  0.7411  0.4412  0.1914  0.0728  0.0275    Purdue  3  South  1.0000  0.9398  0.6942  0.3801  0.1453  0.0517  0.0193    Texas Tech  3  West  1.0000  0.9165  0.6242  0.3324  0.1060  0.0427  0.0160    Auburn  5  Midwest  1.0000  0.7955  0.5087  0.1826  0.0935  0.0312  0.0093    Virginia Tech  4  East  1.0000  0.9012  0.5951  0.1621  0.0678  0.0277  0.0080    Houston  3  Midwest  1.0000  0.9020  0.5159  0.2142  0.0721  0.0193  0.0056    Wisconsin  5  South  1.0000  0.7462  0.4815  0.1321  0.0573  0.0158  0.0042    Florida St.  4  West  1.0000  0.8603  0.5624  0.1190  0.0493  0.0144  0.0040    Buffalo  6  West  1.0000  0.7971  0.3297  0.1366  0.0336  0.0110  0.0033    Louisville  7  East  1.0000  0.7231  0.1890  0.1093  0.0288  0.0110  0.0033    LSU  3  East  1.0000  0.8281  0.5024  0.1455  0.0378  0.0121  0.0030    Kansas  4  Midwest  1.0000  0.8524  0.3988  0.1145  0.0476  0.0111  0.0020    Iowa St.  6  Midwest  1.0000  0.6897  0.3652  0.1494  0.0486  0.0123  0.0017    Kansas St.  4  South  1.0000  0.8050  0.3783  0.0852  0.0297  0.0061  0.0015    Marquette  5  West  1.0000  0.6964  0.3216  0.0455  0.0161  0.0035  0.0013    Mississippi St.  5  East  1.0000  0.8290  0.3609  0.0747  0.0233  0.0063  0.0010    Wofford  7  Midwest  1.0000  0.6854  0.2001  0.0909  0.0237  0.0056  0.0009    Villanova  6  South  1.0000  0.6152  0.2016  0.0725  0.0179  0.0029  0.0006    Nevada  7  West  1.0000  0.5528  0.1717  0.0652  0.0127  0.0026  0.0006    Maryland  6  East  1.0000  0.7421  0.3775  0.0956  0.0215  0.0057  0.0005    Utah St.  8  Midwest  1.0000  0.5534  0.0668  0.0184  0.0041  0.0009  0.0003    Cincinnati  7  South  1.0000  0.5308  0.1392  0.0442  0.0078  0.0014  0.0002    Yale  14  East  1.0000  0.1719  0.0457  0.0044  0.0005  0.0002  0.0002    Florida  10  West  1.0000  0.4472  0.1223  0.0390  0.0064  0.0014  0.0001    Syracuse  8  West  1.0000  0.5412  0.0490  0.0193  0.0063  0.0013  0.0001    Saint Mary’s (CA)  11  South  1.0000  0.3848  0.0944  0.0259  0.0039  0.0007  0.0001    UCF  9  East  1.0000  0.4608  0.0406  0.0099  0.0020  0.0005  0.0001    Baylor  9  West  1.0000  0.4588  0.0377  0.0130  0.0031  0.0004  0.0001    Iowa  10  South  1.0000  0.4692  0.1131  0.0352  0.0064  0.0007  0.0000    VCU  8  East  1.0000  0.5392  0.0557  0.0165  0.0032  0.0007  0.0000    Oklahoma  9  South  1.0000  0.5250  0.0609  0.0220  0.0055  0.0006  0.0000    Ole Miss  8  South  1.0000  0.4750  0.0549  0.0194  0.0054  0.0006  0.0000    Washington  9  Midwest  1.0000  0.4466  0.0445  0.0108  0.0019  0.0003  0.0000    Minnesota  10  East  1.0000  0.2769  0.0324  0.0128  0.0016  0.0003  0.0000    Ohio St.  11  Midwest  1.0000  0.3103  0.1036  0.0275  0.0045  0.0002  0.0000    Seton Hall  10  Midwest  1.0000  0.3146  0.0522  0.0149  0.0021  0.0002  0.0000    Murray St.  12  West  1.0000  0.3036  0.0836  0.0079  0.0011  0.0002  0.0000    Oregon  12  South  1.0000  0.2538  0.1059  0.0124  0.0024  0.0001  0.0000    New Mexico St.  12  Midwest  1.0000  0.2045  0.0705  0.0090  0.0021  0.0001  0.0000    Temple  11  East  0.4049  0.0883  0.0199  0.0018  0.0003  0.0001  0.0000    Belmont  11  East  0.5951  0.1696  0.0545  0.0074  0.0009  0.0000  0.0000    Vermont  13  West  1.0000  0.1397  0.0324  0.0021  0.0005  0.0000  0.0000    UC Irvine  13  South  1.0000  0.1950  0.0343  0.0024  0.0003  0.0000  0.0000    Arizona St.  11  West  0.5599  0.1223  0.0192  0.0033  0.0001  0.0000  0.0000    Liberty  12  East  1.0000  0.1710  0.0251  0.0018  0.0001  0.0000  0.0000    Northern Ky.  14  West  1.0000  0.0835  0.0145  0.0012  0.0001  0.0000  0.0000    Georgia St.  14  Midwest  1.0000  0.0980  0.0153  0.0010  0.0001  0.0000  0.0000    Saint Louis  13  East  1.0000  0.0988  0.0189  0.0009  0.0001  0.0000  0.0000    Northeastern  13  Midwest  1.0000  0.1476  0.0220  0.0016  0.0000  0.0000  0.0000    St. John’s (NY)  11  West  0.4401  0.0806  0.0124  0.0009  0.0000  0.0000  0.0000    Montana  15  West  1.0000  0.0451  0.0059  0.0009  0.0000  0.0000  0.0000    Old Dominion  14  South  1.0000  0.0602  0.0098  0.0006  0.0000  0.0000  0.0000    Gardner-Webb  16  South  1.0000  0.0134  0.0020  0.0004  0.0000  0.0000  0.0000    Colgate  15  South  1.0000  0.0492  0.0066  0.0003  0.0000  0.0000  0.0000    Abilene Christian  15  Midwest  1.0000  0.0305  0.0031  0.0002  0.0000  0.0000  0.0000    Bradley  15  East  1.0000  0.0176  0.0012  0.0002  0.0000  0.0000  0.0000    Iona  16  Midwest  1.0000  0.0111  0.0010  0.0000  0.0000  0.0000  0.0000    North Dakota St.  16  East  0.7344  0.0061  0.0001  0.0000  0.0000  0.0000  0.0000    N.C. Central  16  East  0.2656  0.0011  0.0000  0.0000  0.0000  0.0000  0.0000    Fairleigh Dickinson  16  West  0.5314  0.0025  0.0000  0.0000  0.0000  0.0000  0.0000    Prairie View  16  West  0.4686  0.0021  0.0000  0.0000  0.0000  0.0000  0.0000      Expected Points Now that we have probabilities that each team reaches each round in the tournament, we can compute the expected number of points a given team will score. Let \\(S_i\\) denote the number of points team \\(i\\) will score in the Statsketball tournament. We see that the expected number of points team \\(i\\) will score, \\(\\mathbb{E}(W_i)\\) is computed as follows: \\[ \\mathbb{E}(S_i) = \\sum_{j = 1}^6 P(\\text{Team } i \\text{ wins in Round } j)\\times(\\text{Points for win in Round } j) \\] It’s not suprising that teams with better seeds tend to have the best expected points. However, given the increased cost, is it necessarily worth it? Looking at a plot of expected points divided by team cost (to get an estimate of how many points we can expected per draft point we spend), it’s clear that many of the 1-seeds, with the expection of Gonzaga, are overvalued.\n Selecting Teams: The Knapsack Problem I’d like to select the teams that maximize the number of expected points in my entry, subject to the budget restriction. This is a version of the classic, Knapsack Problem. In the Knapsack Problem, there are \\(N\\) objects with values \\(p_1, ..., p_n\\) and weights \\(w_1, ..., w_n\\). The problem asks for the most valuable subset of objects that can fit in the backpack, which has weight capacity \\(C\\). In the context of Statsketball, the objects are the teams, values \\(p_i\\) are equal to the expected points scored \\(\\mathbb{E}(S_i)\\), weights \\(w_i\\) are equal to team costs, and the capacity \\(C\\) is our budget of 224 draft points. The Knapsack problem is solved using Dynamic Programming, and there is an implementation of a Knapsack solver in the adagio R package. Note, that we will have to combine the expected points of the First 4 teams because the contest rules only asks that we select the combination of teams in each play-in game slot.\nlibrary(adagio) kn_solved \u0026lt;- knapsack(ncaa_sims$cost, ncaa_sims$exp_pts, 224) kn_solved ## $capacity ## [1] 224 ## ## $profit ## [1] 42.297 ## ## $indices ## [1] 2 18 21 32 35 48 49 51 ncaa_sims$team[kn_solved$indices] ## [1] \u0026quot;Michigan St.\u0026quot; \u0026quot;Kentucky\u0026quot; \u0026quot;Auburn\u0026quot; \u0026quot;Iona\u0026quot; \u0026quot;Purdue\u0026quot; ## [6] \u0026quot;Gardner-Webb\u0026quot; \u0026quot;Gonzaga\u0026quot; \u0026quot;Texas Tech\u0026quot; We aren’t expecting much from either of the 16 seeds, Gardner-Webb and Iona, but those are simply chosen in order to not be wasteful. Not suprisingly, the teams chosen are among the best value picks in seeds 1-5 identified above.\n Limitations There are two main limitations of maximizing expected points. The first, is that we don’t know what teams other entrants to the Statsketball tournament are selecting. Any team that is selected by several entrants becomes relatively less valuable. Another limitation is that maximizing expected points yields fewer teams chosen. Many times, we can obtain 90% of the expected points of 1 team for the same (or lower) cost using some combination of 2 or 3 teams. Having lots of teams sounds great in practice, as we keep more doors open in case of upsets, but at the same time, the lower seeded a team is, the less likely it is to exceed it’s expected value. Many distributions of team points in statsketball will be heavily skewed towards 0, as lower seeded teams are likely to be knocked out in round 1 of the tournament. Because we are comparing means and not distributions, there might be some other combination of teams with a lower expected value that is more likely to outscore the group of teams I’ve selected.\nBy no means is this method perfect, but I think it does a reasonably good job of identifying and selecting undervalued teams given the cost constraints of the tournament.\n  ","date":1552953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552953600,"objectID":"da0c8ed542ea61b9b7a62d53c40aebd0","permalink":"https://lukebenz.com/post/statsketball/","publishdate":"2019-03-19T00:00:00Z","relpermalink":"/post/statsketball/","section":"post","summary":"Below is my submission methodology for the 2019 American Statistical Association Statsketball Draft Challenge. Having won the contest in 2018, I knew that I had to up my game this year to defend my crown.\nContest Background The Statsketball Draft Challenge asks participants the chance to select NCAA Tournament Teams using a budget of 224 draft points. The cost of each team, in draft points, is based on the team’s seed.","tags":["NCAA Basketball"],"title":"Statsketball 2019","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://lukebenz.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" Introduction One of the more unique student sections in college basketball belongs to the Arizon State Sun Devils and their famous “Curtain of Distraction”. The Curtain of Distraction opens to reveal students in ridiculous attire trying to do all they can to break the focus of opposing free throw shooters. Perhaps the most famous attempted distraction occured when Olympic swimmer Michael appeard from behind the curatin wearing only a speedo. Several outlets claim anecdotally that Curtain of Distraction works but don’t offer statistical evidence. Justin Wolfers of The Upshot attempted to quantify the effect of the Curtain of Distraction and found it to increase ASU’s home court advantage by 1-2 points.\nIs the advantage still present (Wolfer’s article was written 4 years ago)? Let’s take a look, using my ncaahoopR R package.\n Exploratory Analysis We’ll first just look at which teams ASU has played at home and how they have faired from the charity stripe in Tempe. We begin by first scraping data for all of Arizona State’s home games for the 2018-19 season.\nlibrary(ncaahoopR) ### Get Arizona State\u0026#39;s Home Games for 2018-19 Season asu_home_games \u0026lt;- get_schedule(\u0026quot;Arizona State\u0026quot;) %\u0026gt;% filter(date \u0026lt;= Sys.Date(), location == \u0026quot;H\u0026quot;) ### Get Arizona State\u0026#39;s Roster asu_roster \u0026lt;- get_roster(\u0026quot;Arizona State\u0026quot;) ### Get play by play data for all of Arizona State\u0026#39;s home games this year pbp_data \u0026lt;- get_pbp_game(asu_home_games$game_id) Next, we can tag free throws as made/missed and by which team attempted the free throw.\n### Extract Free Throws free_throws \u0026lt;- filter(pbp_data, grepl(\u0026quot;Free Throw\u0026quot;, description)) ### Tag Free Throw Team free_throws$ft_team \u0026lt;- NA for(i in 1:nrow(free_throws)) { free_throws$ft_team[i] \u0026lt;- case_when(any(sapply(asu_roster$name, grepl, free_throws$description[i])) ~ free_throws$home[i], T ~ free_throws$away[i]) } free_throws$made \u0026lt;- grepl(\u0026quot;made\u0026quot;, free_throws$description) Next, we’ll aggregate the results. Since play-by-play data isn’t availble for Arizona State’s home contest against Oregon State, I’ve manually added the free throw stats from that game.\nsum_stats \u0026lt;- group_by(free_throws, ft_team) %\u0026gt;% summarise(\u0026quot;n_made\u0026quot; = sum(made), \u0026quot;n_attempts\u0026quot; = n(), \u0026quot;ft_pct\u0026quot; = mean(made)) %\u0026gt;% ungroup() %\u0026gt;% filter(ft_team != \u0026quot;Arizona State\u0026quot;) %\u0026gt;% bind_rows(tibble(\u0026quot;ft_team\u0026quot; = \u0026quot;Oregon State\u0026quot;, \u0026quot;n_made\u0026quot; = 13, \u0026quot;n_attempts\u0026quot; = 20, \u0026quot;ft_pct\u0026quot; = 0.65)) %\u0026gt;% arrange(desc(ft_pct)) knitr::kable(sum_stats)  A More In-Depth Look Of course, these numbers don’t mean much in context. Perhaps Kansas is a really good free throw shooting team or McNeese is a really bad free throw shooting team to begin with. What we are really interested in is how team’s free-throw shooting differs from their season-average when they play against Arizona State. Specifically, we’ll look at home a team’s season-averge FT% in other true road compares to road games at ASU.\n### Loop over ASU Home Opponent for(i in 1:nrow(asu_home_games)) { ### Get ESPN Name of ASU Home Opponent opp \u0026lt;- dict$ESPN[dict$ESPN_PBP == asu_home_games$opponent[i]] if(length(opp) == 0) { opp \u0026lt;- asu_home_games$opponent[i] } if(opp == \u0026quot;McNeese\u0026quot;) { opp \u0026lt;- \u0026quot;Mcneese\u0026quot; } if(opp == \u0026quot;Long Beach State\u0026quot;) { opp \u0026lt;- \u0026quot;Long Beach St\u0026quot; } ### Get Opponent\u0026#39;s PBP Data opp_away_pbp \u0026lt;- get_schedule(opp) %\u0026gt;% filter(date \u0026lt;= Sys.Date(), location == \u0026quot;A\u0026quot;) %\u0026gt;% pull(game_id) %\u0026gt;% get_pbp_game() opp_roster \u0026lt;- get_roster(opp) ### Tag Free Throws opp_free_throws \u0026lt;- filter(opp_away_pbp, grepl(\u0026quot;Free Throw\u0026quot;, description)) opp_free_throws$ft_team \u0026lt;- NA for(i in 1:nrow(opp_free_throws)) { opp_free_throws$ft_team[i] \u0026lt;- case_when(any(sapply(opp_roster$name, grepl, opp_free_throws$description[i])) ~ opp_free_throws$away[i], T ~ opp_free_throws$home[i]) } if(opp == \u0026quot;Mcneese\u0026quot;) { opp \u0026lt;- \u0026quot;McNeese\u0026quot; } if(opp == \u0026quot;Long Beach St\u0026quot;) { opp \u0026lt;- \u0026quot;Long Beach State\u0026quot; } opp_free_throws \u0026lt;- filter(opp_free_throws, ft_team == opp) opp_free_throws$made \u0026lt;- grepl(\u0026quot;made\u0026quot;, opp_free_throws$description) ### Aggregate Game by Game Opponent FT Stats opp_season_stats \u0026lt;- group_by(opp_free_throws, home) %\u0026gt;% summarise(\u0026quot;n_made\u0026quot; = sum(made), \u0026quot;n_attempts\u0026quot; = n(), \u0026quot;ft_pct\u0026quot; = mean(made)) %\u0026gt;% ungroup() %\u0026gt;% mutate(\u0026quot;team\u0026quot; = opp) ### Save Results if(!exists(\u0026quot;ft_stats\u0026quot;)) { ft_stats \u0026lt;- opp_season_stats }else{ ft_stats \u0026lt;- bind_rows(ft_stats, opp_season_stats) } } ft_stats \u0026lt;- bind_rows(ft_stats, tibble(\u0026quot;home\u0026quot; = \u0026quot;Arizona State\u0026quot;, \u0026quot;n_made\u0026quot; = 13, \u0026quot;n_attempts\u0026quot; = 20, \u0026quot;ft_pct\u0026quot; = 0.65, \u0026quot;team\u0026quot; = \u0026quot;Oregon State\u0026quot;)) Let’s plot free throw shooting by game and visually see what’s going on.\nggplot(ft_stats, aes(x = ft_pct, y = team)) + geom_point(aes(color = (home != \u0026quot;Arizona State\u0026quot;))) + theme_bw() + theme(legend.position = \u0026quot;bottom\u0026quot;, plot.title = element_text(size = 16, hjust = 0.5), plot.subtitle = element_text(size = 12, hjust = 0.5), axis.title = element_text(size = 14)) + labs(x = \u0026quot;Free Throw Percentage\u0026quot;, y = \u0026quot;Team\u0026quot;, col = \u0026quot;Home Team\u0026quot;, title = \u0026quot;Arizona State Opponent\u0026#39;s Free Throw Shooting\u0026quot;, subtitle = \u0026quot;True Road Games Only\u0026quot;) + scale_color_manual(values = c(ncaa_colors$secondary_color[ncaa_colors$espn_name == \u0026quot;Arizona State\u0026quot;], ncaa_colors$primary_color[ncaa_colors$espn_name == \u0026quot;Arizona State\u0026quot;]), labels = c(\u0026quot;Arizona State\u0026quot;, \u0026quot;Other\u0026quot;)) A few play-by-play logs are not available on ESPN, but we have more than enough games to suggest that the effect of the Curtain of Distraction is reduced this year. Three teams had their best road FT shooting performance against the Sun Devils, while the majority of the others seem to fall within the reasonable range one would expect given their other performances. In fact, we can actually quantify how likely each shooting performance at ASU was. Assume that the number of free on opponent took against Arizona State follows a binomial\\((n,p)\\) distribution where \\(n\\) denotes the number of free throw attempts against ASU and \\(p\\) denotes the percentage of free throws that opponent missed in it’s other true road games. We then get the likelihood of each shooting performance against ASU as follows:\nseason_ft_stats \u0026lt;- filter(ft_stats, home != \u0026quot;Arizona State\u0026quot;) %\u0026gt;% group_by(team) %\u0026gt;% summarise(\u0026quot;n_made\u0026quot; = sum(n_made), \u0026quot;n_attempts\u0026quot; = sum(n_attempts), \u0026quot;ft_pct\u0026quot; = n_made/n_attempts) %\u0026gt;% ungroup() p_performance \u0026lt;- rep(NA, nrow(season_ft_stats)) p \u0026lt;- rep(NA, nrow(season_ft_stats)) n_miss \u0026lt;- rep(NA, nrow(season_ft_stats)) n_attempts \u0026lt;- rep(NA, nrow(season_ft_stats)) for(i in 1:nrow(season_ft_stats)) { opp \u0026lt;- season_ft_stats$team[i] game \u0026lt;- filter(ft_stats, home == \u0026quot;Arizona State\u0026quot;, team == opp) n_miss[i] \u0026lt;- game$n_attempts - game$n_made n_attempts[i] \u0026lt;- game$n_attempts p[i] \u0026lt;- 1 - season_ft_stats$ft_pct[season_ft_stats$team == opp] p_performance[i] \u0026lt;- 1 - pbinom(n_miss[i] - 1, n_attempts[i], p[i]) } tibble(\u0026quot;team\u0026quot; = season_ft_stats$team, \u0026quot;p_value\u0026quot; = p_performance) %\u0026gt;% arrange(desc(p_value)) %\u0026gt;% knitr::kable() We see that none of the 12 opponent shooting performances differ from those teams’ normal road free throw shooting behavior in a statistically significant manner. That is to say, there is no evidence to suggest the Curtain of Distraction has had any major impact on opponent free throw shooting this season. We can see this visually in the below graphic.\nset.seed(123) for(i in 1:nrow(season_ft_stats)) { df \u0026lt;- tibble(\u0026quot;miss\u0026quot; = rbinom(100000, n_attempts[i], p[i]), \u0026quot;team\u0026quot; = season_ft_stats$team[i], \u0026quot;n_miss\u0026quot; = n_miss[i]) if(i == 1) { sim_results \u0026lt;- df }else{ sim_results \u0026lt;- bind_rows(sim_results, df) } } ggplot(sim_results, aes(x = miss)) + facet_wrap(~team) + geom_histogram(bins = 23, aes(fill = team)) + geom_vline(data = .%\u0026gt;% group_by(team) %\u0026gt;% summarise(\u0026quot;miss\u0026quot; = max(n_miss)), aes(xintercept = miss), lty = 2) + theme_minimal() + theme(legend.position = \u0026quot;none\u0026quot;, plot.title = element_text(size = 16, hjust = 0.5), plot.subtitle = element_text(size = 12, hjust = 0.5), axis.title = element_text(size = 14), axis.text.y = element_blank()) + labs(x = \u0026quot;Free Throws Missed\u0026quot;, y = \u0026quot;Frequency\u0026quot;, title = \u0026quot;Expected Distributions of Missed Free Throws Against ASU\u0026quot;, subtitle = \u0026quot;Under Null Hypothesis of No Curtain Effect\u0026quot;) + scale_fill_manual(values = c(\u0026quot;#CC0033\u0026quot;, \u0026quot;#CFB87C\u0026quot;, \u0026quot;#00274C\u0026quot;, \u0026quot;#0051BA\u0026quot;, \u0026quot;#FFC72A\u0026quot;, \u0026quot;#FDD023\u0026quot;, \u0026quot;#000000\u0026quot;, \u0026quot;#154733\u0026quot;, \u0026quot;#DC4405\u0026quot;, \u0026quot;#FF671F\u0026quot;, \u0026quot;maroon\u0026quot;, \u0026quot;#CC0000\u0026quot;))  Conclusion There is strong evidence to suggest that the Curtain of Distraction isn’t doing much to distract opposing free throw shooters this year. This differs from the conclusion of the Upshot piece from several years ago, but doesn’t necessarily contradict it. At the time of the Upshot article, the Curtain of Distraction had only been in existence for two years. Now, four years later, Pac 12 opponents have faced the student section several times, and teams perhaps now know what to prepare for. In any case, future research will examine when such a decline in the significance of distracting took place, and whether the trend has been on a steady decline over the last four years or whether this year is somewhat of a statistical fluke.\n ","date":1549238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549238400,"objectID":"b5cf346a3b2814e291554e79355e8f0b","permalink":"https://lukebenz.com/post/asu_curtain/","publishdate":"2019-02-04T00:00:00Z","relpermalink":"/post/asu_curtain/","section":"post","summary":"Introduction One of the more unique student sections in college basketball belongs to the Arizon State Sun Devils and their famous “Curtain of Distraction”. The Curtain of Distraction opens to reveal students in ridiculous attire trying to do all they can to break the focus of opposing free throw shooters. Perhaps the most famous attempted distraction occured when Olympic swimmer Michael appeard from behind the curatin wearing only a speedo.","tags":["NCAA Basketball","ncaahoopR"],"title":"Does Arizona State's Curtain of Distraction Work?","type":"post"},{"authors":null,"categories":null,"content":"I write for midmajormadness.com covering NCAA basketball analytics and Ivy League hoops. Below is a complete list of my stories for the website.\n Ivy League Tiebreaking Scenarios 2020 (03/01/2020) Charts! This Season in Win Probability (12/30/2019) ShotTracker and the Mountain West are at the forefront of the next phase in college basketball’s analytics revolution (6/4/2019)  ","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"24ec0fca2703830b86c3ad5ec87a3d84","permalink":"https://lukebenz.com/project/mid_madness/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project/mid_madness/","section":"project","summary":"A complete list of my articles for [midmajormadness.com](www.midmajormadness.com)","tags":["Data Journalism"],"title":"Mid Major Madness","type":"project"},{"authors":["Luke Benz"],"categories":[],"content":" Introduction One of the NCAA Men’s Basketball metrics I’ve been fascinated with lately is that of Game Excitement Index. Game Excitement Index (GEI) attempts to quantify how exciting a particular game was after it has been played. Related metrics have been implemented for NFL games by Brian Burke, NBA games by InPredict (Mike Beuoy), and for March Madness by FiveThirtyEight. One can compute GEI for college basketball games using my ncaahoopR package, which I define as follows:\n\\[ \\text{GEI} = \\frac{2400}{t}\\sum_{i = 2}^n |p_i - p_{i-1}| \\] where \\(t\\) is the length of the game (in seconds), \\(n\\) is the number of plays in the game, and \\(p_i\\) is the home team’s win probability on play \\(i\\) of the game. One can think of GEI as a measure of the length of the win probability curve if it were to be unwound, normalized to the length of a standard regulation game. The reason I choose to normalize the length of games is that I don’t want sloppy “boring” games which simply happen to go to 2 or 3 overtimes to be pegged as more exciting. In general, this small normalization has little effect, as games that go deep into overtime are generally pretty exciting to begin with. Through this article, I hope to explore which games, teams, and conferences have produced the most exciting basketball this season, while showing off how one can use ncaahoopR to answer interesting college basketball questions.\n Obtaining the Data The below code uses ncaahoopR to\n Get each team’s schedule Compute GEI for each game this season  Note that a complete list of team’s can be found in the ids data frame built into the package.\nlibrary(ncaahoopR) ### Scrape All Schedules i \u0026lt;- 1 for(team in ids$team) { print(paste(\u0026quot;Getting Team:\u0026quot;, i, \u0026quot; of \u0026quot;, 353)) schedule \u0026lt;- get_schedule(team) %\u0026gt;% filter(date \u0026lt; Sys.Date()) %\u0026gt;% mutate(\u0026quot;team\u0026quot; = team) if(i == 1) { master \u0026lt;- schedule }else{ master \u0026lt;- rbind(master, schedule) } i \u0026lt;- i + 1 } ### Get Unique Game IDs game_ids \u0026lt;- filter(master, !duplicated(game_id)) %\u0026gt;% pull(game_id) %\u0026gt;% unique() ### Compute GEI for Each Game n \u0026lt;- length(game_ids) df \u0026lt;- data.frame(\u0026quot;game_id\u0026quot; = game_ids, \u0026quot;gei\u0026quot; = NA) for(i in 1:nrow(df)) { print(paste(\u0026quot;GEI:\u0026quot;, i, \u0026quot;of\u0026quot;, n)) df$gei[i] \u0026lt;- game_excitement_index(game_ids[i]) } master \u0026lt;- left_join(master, df, by = \u0026quot;game_id\u0026quot;)  Analysis Below is a histogram of the Game Excitement Index for the 2018-19 season (for all games play-by-play data is avaiable). Through the first 6 weeks of the season, GEI has a mean of roughly 3.6 and standard deviation of about 2.6. GEI appears to follow some sort of Gamma distribution. The distribution is skewed right, with over 62 percent of games registing GEI less than 4. We can see looking by the plot above that very few games have GEI greater than 10. In fact, 10 is the 99th percentile for GEI, and through 12/21/2018, only 23 games have achieved such a mark. Below are the most exciting games of the season.\n  team opponent date location team_score opp_score gei    St John’s VCU 2018-11-20 N 87 86 14.34  Kentucky Seton Hall 2018-12-08 N 83 84 12.49  Louisville Michigan State 2018-11-27 H 82 78 11.27  Campbell UNC Wilmington 2018-11-06 H 97 93 11.14  Hampton Norfolk State 2018-11-29 A 89 94 11.10  UMass Lowell Wagner 2018-11-10 H 88 84 10.86  Columbia Fordham 2018-11-18 A 69 70 10.79  BYU Illinois State 2018-11-28 A 89 92 10.75  SMU Wright State 2018-11-21 N 77 76 10.72  Columbia Delaware 2018-12-02 H 86 87 10.59  Texas State UTSA 2018-12-01 A 69 68 10.52  Santa Clara USC 2018-12-18 H 102 92 10.48  Boston College Providence 2018-12-04 H 95 100 10.47  E Kentucky Northern Kentucky 2018-12-08 H 76 74 10.46  LIU Brooklyn Milwaukee 2018-11-20 A 87 92 10.44  Iona Long Beach State 2018-11-19 N 85 86 10.32  Towson UMBC 2018-12-11 A 80 76 10.25  BYU UNLV 2018-12-15 N 90 92 10.24  Fairfield LIU Brooklyn 2018-11-13 H 87 89 10.22  American UMBC 2018-11-24 A 73 69 10.18  Abil Christian Pacific 2018-11-23 A 73 71 10.04  Denver Wyoming 2018-12-11 A 90 87 10.02  N Illinois Northern Kentucky 2018-11-09 H 85 88 10.01    Let’s take a closer look at the most exciting game of the season, VCU vs. St. John’s, an OT thriller in the Legend’s Classic championship game, during Thanksgiving “Feast Week”. We can make the win probability chart for the game using the function gg_wp_chart(), as follows.\ngg_wp_chart(game_id = 401096927, home_col = \u0026quot;black\u0026quot;, away_col = \u0026quot;red\u0026quot;) Next, we can look at which teams have the highest and lowest average GEI. Due to the skewed nature of the GEI distribution, it probably makes most sense to rank teams by median GEI. We can also classify games into a few different categories based on their GEI:\n Heart Pounders: GEI \u0026gt; 8 Thrillers: 4 \u0026lt; GEI \\(\\leq\\) 8 Average Games: 1 \u0026lt; GEI \\(\\leq\\) 4 Duds: GEI \u0026lt; 1  Most Exciting Teams ## `summarise()` ungrouping output (override with `.groups` argument)     team median_gei mean_gei max_gei min_gei heart_pounders thrillers average_games duds    American 7.43 6.26 10.18 0.98 3 2 1 1  San Jose State 7.15 6.27 9.85 1.05 4 2 2 0  Delaware 7.05 6.17 10.59 2.43 3 4 3 0  UMKC 6.97 6.93 9.42 4.38 1 2 0 0  Harvard 6.87 6.43 9.26 2.03 2 4 1 0  Iona 6.85 6.58 10.32 1.14 3 3 2 0  Fordham 6.66 5.62 10.79 0.48 2 4 2 1  Seton Hall 6.46 5.79 12.49 0.74 2 3 3 1  Wyoming 6.39 5.36 10.02 1.05 2 5 4 0  VCU 6.11 7.38 14.34 3.66 1 3 1 0  CSU Bakersfield 6.07 5.52 9.14 1.77 1 5 2 0  Niagara 5.97 6.18 9.92 1.50 2 7 1 0  Ga Southern 5.91 5.10 7.96 1.61 0 8 3 0  Arizona State 5.89 4.87 9.55 0.56 2 4 2 2  Saint Joe’s 5.82 5.31 8.42 1.46 1 3 1 0  Belmont 5.78 5.30 8.13 1.88 1 5 2 0  High Point 5.74 5.03 9.25 1.15 2 4 5 0  Lafayette 5.74 5.27 8.75 0.59 3 3 3 1  Indiana 5.62 4.39 9.41 0.34 2 4 2 3  Pacific 5.60 5.46 10.04 1.06 3 3 4 0     Least Exciting Teams     team median_gei mean_gei max_gei min_gei heart_pounders thrillers average_games duds    MD-E Shore 0.53 1.31 5.35 0.23 0 1 2 8  AR-Pine Bluff 0.61 1.21 5.14 0.30 0 1 2 6  Miss Valley St 0.67 0.83 1.72 0.32 0 0 2 7  Texas Tech 0.68 2.63 7.68 0.26 0 4 0 6  Coppin State 0.73 1.45 8.29 0.30 1 0 2 7  Illinois 0.77 1.14 2.16 0.48 0 0 1 2  Chicago State 0.80 2.46 8.19 0.38 1 3 1 7  Alabama State 0.84 1.23 2.84 0.31 0 0 3 6  Auburn 0.94 2.18 7.80 0.24 0 2 2 5  Alcorn State 0.95 1.30 3.07 0.44 0 0 5 5  Virginia Tech 0.95 2.48 8.45 0.39 1 1 2 5  Georgia Tech 0.99 2.60 7.25 0.39 0 3 1 4  NC State 1.00 2.52 8.50 0.23 1 2 3 5  S Carolina St 1.00 1.87 5.92 0.39 0 2 4 6  UNC Asheville 1.01 2.47 7.52 0.34 0 2 3 4  Saint Mary’s 1.03 0.98 1.35 0.69 0 0 3 2  UNC 1.03 2.16 6.38 0.46 0 1 4 4  TCU 1.13 2.51 7.13 0.64 0 1 1 2  Duke 1.16 2.23 9.80 0.25 1 1 5 5  Maine 1.23 2.07 5.27 0.30 0 2 2 3    Perhaps not suprisingly, many of the least exciting teams so far are MEAC and SWAC teams, often scheduling buy-games (and getting blown-out) against high-major opponents. Teams like Duke, UVA, and Texas Tech are likely on the list for the same reason–scheduling and destroying many weaker opponents. Duke’s appearance on this list is actually a testament to it’s domiance this season. Even having Kentucky, Texas Tech, Auburn, Indiana, and Gonzaga on it’s non-conference schedule, it’s level of dominance means Duke’s win probability charts flatline early and are marked by low GEI scores. This also shows a limitation of GEI to show what is exciting. Against most opponents, a team like Duke will still be fairly heavily favored when the score is close and as such, won’t be able to wrack up as high of a Game Excitement Index. Perhaps at this stage of the season, GEI is best used to rank mid-major teams, and it would be wise to wait until conference play begins to evalaute high-major teams on this metric.\n GEI Game Types by Conference  Most Exciting Game by Date Finally, one can look at the most exciting game on each day of the season. I got the idea for the below chart from Jordan Sperber’s look at the best ranked games each day per KenPom FanMatch, which seeks to quantify the quality of a game before it is played.\nBy no means is GEI meant to be a perfect metric, and it might fail to capture important aspects of the game that a given individual might find to be exciting. That being said, I think it does a pretty good job of capturing a lot of what makes games fun to watch, and helps raise awareness of a lot of good mid-major basketball that often flies under the radar. I’ll keep updating these materials as conference play kicks off in the coming weeks to see if/how the metric changes, but for now, we can sit back, relax, and appreciate some good college hoops.\n  ","date":1545436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545436800,"objectID":"696c516693ed8f59ca6fbd7a2b03e621","permalink":"https://lukebenz.com/post/gei/","publishdate":"2018-12-22T00:00:00Z","relpermalink":"/post/gei/","section":"post","summary":"Introduction One of the NCAA Men’s Basketball metrics I’ve been fascinated with lately is that of Game Excitement Index. Game Excitement Index (GEI) attempts to quantify how exciting a particular game was after it has been played. Related metrics have been implemented for NFL games by Brian Burke, NBA games by InPredict (Mike Beuoy), and for March Madness by FiveThirtyEight. One can compute GEI for college basketball games using my ncaahoopR package, which I define as follows:","tags":["NCAA Basketball","ncaahoopR"],"title":"Game Excitement Index: An In-Depth Exploration","type":"post"},{"authors":["Luke Benz","Joeky Senders","Jeffry Wefel","Elizabeth Claus"],"categories":null,"content":"","date":1542240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542240000,"objectID":"ce1d54be25c2308a794418dd9de9e0b6","permalink":"https://lukebenz.com/posters/qol_lgg/","publishdate":"2018-11-15T00:00:00Z","relpermalink":"/posters/qol_lgg/","section":"posters","summary":"Presented at _Society for Neuro-Oncology Annual Scientific Meeting_, New Orleans, LA","tags":null,"title":"The International Low Grade Glioma Registry Patient-Reported Quality of Life","type":"posters"},{"authors":null,"categories":null,"content":" Introduction For the past two years, I’ve been maintaining a men’s college basketball prediction model that I first built for the Yale Undergraduate Sports Analytics Group (YUSAG) during my sophomore year of college. The model has done objectively quite well over the past two seasons. It correctly predicted last year’s National Champion, Villanova, and accurately predicted North Carolina and Gonzaga as the most likely finalists in the 2017 title game. Brackets filled out using model derived predictions have finished above the 90th percentile on ESPN each of the past two seasons. Using my model, I even won the 2018 American Statsitical Association Statsketball Tournament. Having two seasons of experience with this project under my belt, there are a number of additional features I’ve been interested in adding/changing for the 2018-19 season.\n Background Before we get into what’s different this year, we need to look at the way the YUSAG model has worked in the past. The core of the model is linear regression, specified by \\[ Y = \\beta_{team}X_{team} - \\beta_{opp}X_{opp} + \\beta_{loc}X_{loc} + \\epsilon \\]\nwhere \\(X_{team, i}, X_{opp, i}\\), and \\(X_{loc, i}\\) are indicator vectors for the \\(i^{th}\\) game’s team, opponent, and location (Home, Away, Neutral) from the perspective of team, and \\(Y_i\\) is game’s the score-differential. The key assumptions for this model are that game outcomes are independent of one another, and that our error \\(\\epsilon \\sim N(0, \\sigma^2)\\).\n\\(\\beta_{team}\\), nicknamed “YUSAG Coefficients”, were scaled to represent the points better or worse a team was the average college team basketball team on a neutral court. Lastly, \\(\\beta_{loc}\\) is a parameter indicating home-court advantage, estimated to be about 3.2 points.\nNote that the coefficients \\(\\beta_{opp}\\) have the same values and interpretation as \\(\\beta_{team}\\). I’ll note that when this model is actually fit, \\(\\beta_{opp} = -\\beta_{team}\\) but in the interest of easy interpretation in these methodology notes, I have flipped the signs of the \\(\\beta_{opp}\\) coefficients and added a minus sign to the model formulation above.\nLet’s walk through an example to see how this all works. Say Yale is hosting Harvard, and we’d like to predict score differential. \\(\\widehat\\beta_{team = Yale} = -2.1\\) and \\(\\widehat\\beta_{opp = Harvard} = 1.9\\). This means that on a neutral court, Yale is 2.1 points worse than the average college basketball team, and Harvard is 1.9 point better. Our predicted outcome for this game would be as follows: \\[ \\widehat Y_i = \\widehat \\beta_{team = Yale} - \\widehat \\beta_{opp = Harvard} + \\widehat \\beta_{loc = Home} = -2.1 - 1.9 + 3.2 = -0.8 \\] Hence, we’d expect Harvard to win this game by roughly 0.8 points. Of course, we could’ve predicted the game from the perspective of Harvard as well, and we’d get exactly the same answer. Since \\(\\beta_{opp = Yale} = \\beta_{team = Yale}\\) and \\(\\beta_{team = Harvard} = \\beta_{opp = Harvard}\\), we have \\[ \\widehat Y_i = \\widehat \\beta_{team = Harvard} - \\widehat \\beta_{opp = Yale} + \\widehat \\beta_{loc = Away} = 1.9 - (-2.1) - 3.2 = 0.8 \\]\nWe recover the Harvard by 0.8 predicted scoreline, and hence, it doesn’t matter which school we use as “team” or “opponent” because the results are identical. Once we have a predicted score differential, we can convert this to a win probability using logistic regression. I won’t get into the specifics how logistic regressions works in this post, but for the purposes of this example, just think about it as a translation between predicted point spread and predicted win probability.\nOne thing that we check to see is that the win probability model is well calibrated. That is, if we predict a team has a 75% chance of winning, then we should see them win about 75% of the time on out of sample data. To see that the model is well tuned, I’ve fit the logistic regression on data from the 2017-18 season, and then made predictions of win probability from prior predicted score differentials for the 2016-17 season. We don’t see any drastic deviations from the line denoting perfect correspondence between predcited and observed win probability. This is good–it means teams are winning about as often as we predict they are winning!\n Offense and Defense Specific Models Now that we have the basics of model, we can dive into what’s new for this season. In the past, I’ve only been interesting in predicting game score differential, \\(Y_i\\). In fact, we can rewrite score differentials as \\(Y_i = T_i - O_i\\), where \\(T_i\\) denotes team_score and \\(O_i\\) denotes opp_score for game \\(i\\), respectively. Not only is the distribution of score_differential normally distributed, but so too is the distribution of team_score. I’ll note that the gap around 0 in the distribution of score_differential is due to the fact that games can’t end in ties. I’ll also comment that the distribution of opp_score is identical to that of team_score as each game is entered twice in the database, so there is a direct one-to-one correspondence between each value of team_score and opp_score.\nRecall, the sum of two normal random variables is also normally distributed, even if they are not indepent of one another. Thus, using the same linear model framework, we can predict for each game \\(T_i\\) and \\(O_i\\). That is, in addition to a predicted score differential, we can actually predict the number of points each team will score. As a consqeuence, we can obtaining estimates of team offensive and defensive coefficeints, \\(\\alpha_{team}\\) and \\(\\delta_{team}\\), respectively. To be clear, this is not necessarily a different model, but a reparameterization that allows us to learn more informations about the contributions of team strength.\n\\[ Y = \\beta_{team}X_{team} - \\beta_{opp}X_{opp} + \\beta_{loc}X_{loc}\\\\ (T - O) = \\beta_{team}X_{team} - \\beta_{opp}X_{opp} + \\beta_{loc}X_{loc} \\\\ T - O = (\\alpha_{team} - \\delta_{team})X_{team} - (\\alpha_{opp} - \\delta_{opp})X_{opp} + \\beta_{loc}X_{loc} \\\\ T - O = (\\alpha_{team} - \\delta_{team})X_{team} - (\\alpha_{opp} - \\delta_{opp})X_{opp} + \\beta_{loc}X_{loc} + (\\beta_0 - \\beta_0) \\\\ \\] Specifically, we can split the above equation into the following two equations \\[ T = \\beta_0 + \\alpha_{team}X_{team} - \\delta_{opp}X_{opp} + \\beta_{loc, off}X_{loc}\\\\ O = \\beta_0 -\\delta_{team}X_{team} + \\alpha_{opp}X_{opp} + \\beta_{loc, def}X_{loc} \\] where \\(\\beta_{loc, off}\\) and \\(\\beta_{loc, def}\\) denote the contributions to home court advantage to offense and defense, respectively, and \\(\\beta_0\\) is the average number of points scored (for one team) per game across all of college basketball, roughly 73 points. So what is this actually saying? For a given game we predict \\(T\\), the number of points a team will score by\nBegin with the baseline average number of points scored, \\(\\beta_0\\) Add a team specific offensive term, \\(\\alpha_{team}\\). We can interpret \\(\\alpha_{team}\\) as the number of points more than the baseline (\\(\\beta_0\\)) our desired team would score against the average college basketball team on a neutral floor. Subtract an opponent specific defensive term, \\(\\delta_{opp}\\). We can interpret \\(\\delta_{opp}\\) as the number of points fewer than the baseline (\\(\\beta_0\\)) our desired team’s opponent would allow against the average college basketball team on a neutral floor. Add an term to adjust for home court advantage.  By symmetry, our prediction of the number of points our desired team allows, \\(O\\), is calculated in almost exactly the same way. Perhaps the math unnecessarily overcomplicates something fairly straightforward, but I think that the derivation of these formulae show how these offensive and defensive coefficients should be interpreted. It’s easy to want to interpret these as meaures of offensive and defensive strength, but it’s extremely important we don’t fall for this temptation. Rather, we should view \\(\\beta_{team}\\) as estimates of overall team strength, and \\(\\alpha_{team}\\) and \\(\\delta_{team}\\) as indicators of how teams derive their strength. For example, consider the top six teams from the end of the 2017-18 season by offensive and defensive coefficients.\nTop \\(\\alpha_{team}\\)\n## team off_coeff def_coeff yusag_coeff overall_rank ## 1 Villanova 17.98007 7.946133 25.92621 1 ## 2 Oklahoma 15.84885 -4.138373 11.71048 43 ## 3 Duke 15.42955 7.892312 23.32186 2 ## 4 North Carolina 14.85430 3.956107 18.81041 8 ## 5 Xavier 14.26454 2.986246 17.25079 13 ## 6 Kansas 12.73801 6.421469 19.15948 7 Top \\(\\delta_{team}\\)\n## team off_coeff def_coeff yusag_coeff overall_rank ## 1 Virginia -2.383885 23.25942 20.87554 5 ## 2 Cincinnati 2.420159 16.90140 19.32156 6 ## 3 Syracuse -2.952363 14.43724 11.48487 45 ## 4 Michigan 4.521445 14.09245 18.61390 9 ## 5 Texas Tech 4.553551 13.00919 17.56274 11 ## 6 Tennessee 5.024089 12.07138 17.09547 14 We see the pitfall of interpreting \\(\\alpha_{team}\\) and \\(\\delta_{team}\\) as direct measures of offensive and defensive strength most noticably in the case of Virginia. We might be tempted to say that Virgina had a below average offense in 2017-18. This is not exactly the case. On a points per game basis, UVA scored fewer points than the average college basketball team, but this is because their elite defense would often slow down the game, leaving fewer possessions for their offense to score. Adjusted for tempo, UVA had a top-25 offense last season. Their overall team strength is nicely captured by their YUSAG Coefficient, \\(\\beta_{team}\\). \\(\\alpha_{team}\\) and \\(\\delta_{team}\\) illustrate that Virginia derives it’s strength from suffocating defense, but shouldn’t be used to rank teams offensively and defensively, at least not in a vaccuum. If one feels so inclined to utilize \\(\\alpha_{team}\\) and \\(\\delta_{team}\\) to comment about an individual team’s offense and defense, they might look at the difference between the two coefficients in an attempt to quantify team balance and see which facet of the game, if any dominates, team play. For example, compare Virginia’s defense first style of play with the more balanced approaches of Villanova, Duke, and Kansas. Not adjusting for tempo is not problematic provided that we are clear on the subtleties of interpreting the model coefficients. This is a big enough point that I’ll repeat it again:\n Only \\(\\beta_{team}\\) should be used when ranking teams based on team strength. These coefficients CAN be used to make statements such as, “Duke is the best team”, and “the average Ivy League team is worse than the average team from the Missouri Valley Conference”. \\(\\alpha_{team}\\) and \\(\\delta_{team}\\) are useful for ranking how many points a team would score/allow relative to average against the average college basketball team at a neutral site. These coefficients should NOT be used to make claims “Virginia has a worse offense than Duke” or “Oklahoma has the second best offense”.   Preseason Priors One challenge with any sports rating system is setting rankings at the beginning of a season. This problem is magnified in any college sport, where teams lose a significant number of their key players from year to year due to transfers, graduation, and the NBA draft. Moreover, teams welcome new recruits and incoming transfers, meaning the year to year difference is any given team’s roster can be quite significant. I’ve tried to deal with these issues in the past at the beginning of a given season, but now that I have three full years of archived rankings (2016-17, 2017-18, and a backcaluated version on 2014-15) I can do a lot better. Let’s look at the year to year stability of our different types of coefficients \\(\\alpha_{team}\\), \\(\\delta_{team}\\), and \\(\\beta_{team}\\).\nWe see that there is higher year to year variability in the offensive coefficients than in the defensive coefficients. So if we can account for some of the year to year variation due to some of the factors surrounding why a team’s roster from year to year, this can help us set good preseason ratings. While my system doesn’t make use of individual player data in-season, I think that it allows us to extract the most information out of how teams change from year to year. All of the the individual level data was graciously given to me by Bart Torvik, who honestly has one of the coolest sites on the internet if you’re a college hoops fan. Bart keeps track of a player value metric called, “Points Over Replacement Player Per Adjusted Game At That Usage”, or more simply PPG! . Examining returning players who played at least 40% of possible minutes for their teams, I computed team level returing PPG!, departing PPG!, and incoming transfer PPG! . Additionly, Bart provided me with team level percetange of returning minutes. Combining that with my own recruiting data pulled from 247Sports.com, I used the several variables to predict offensive and defensive coefficients from the the previous years statistics. Regressions were fit on data 2015-16 \\(\\rightarrow\\) 2016-17 and 2016-17 \\(\\rightarrow\\) 2017-18 using 10-fold cross validiation. The following variables comprised the models.\n\\(\\alpha_{team}^{\\text{year =} i+1}\\)  \\(\\alpha_{team}^{\\text{year =} i}\\) 247Sports Composite Recruiting Score (for Incoming Recruiting Class) Returning PPG! Departing PPG! Indicator for having at least 1 5-Star Recruit Indicator for having at least 3 5-Star Recuits Indicator for having at least 3 3-Star, 4-Star or 5-Star Recuits  Model \\(R^2 = 0.59\\)\n \\(\\delta_{team}^{\\text{year =} i+1}\\)  \\(\\delta_{team}^{\\text{year =} i}\\) 247Sports Composite Recruiting Score (for Incoming Recruiting Class) Returning PPG! Departing PPG! Indicator for having at least 3 5-Star Recuits  Model \\(R^2 = 0.59\\)\nFrom this, not only get a much improved preseason estimate of a team’s true strength (\\(\\hat \\gamma_{team} = \\hat \\alpha_{team} + \\hat \\delta_{team}\\)), but we can also get a prior distribution on the these coefficients as well, utilizing the variance of \\(\\hat \\gamma_{team}\\). Perhaps not suprisingly, the uncertainty in these distributions is greater for teams with more high level recruits and fewer returning players. Compare the following preseason priors for some of the more interesting teams this year.\nLet’s take a look at the top-25 teams heading into the 2018-19 season.\n## team yusag_coeff ## 1 North Carolina 21.29206 ## 2 Villanova 20.00146 ## 3 Michigan St. 19.94314 ## 4 Kentucky 19.14156 ## 5 Duke 18.63643 ## 6 Nevada 18.04865 ## 7 Kansas 17.74140 ## 8 Virginia 17.46613 ## 9 Tennessee 17.42049 ## 10 Gonzaga 17.28193 ## 11 Florida 17.25448 ## 12 Mississippi St. 16.70156 ## 13 Maryland 16.18948 ## 14 West Virginia 15.95730 ## 15 Syracuse 15.93676 ## 16 LSU 15.42715 ## 17 Purdue 14.68644 ## 18 Virginia Tech 14.44185 ## 19 Michigan 14.42888 ## 20 Indiana 14.25695 ## 21 TCU 14.19995 ## 22 Clemson 14.05680 ## 23 Oregon 13.80570 ## 24 Texas 13.77246 ## 25 Kansas St. 13.74995 Lastly, I should make comment on how rankings were detemined for the two new teams to Division 1 this season, Cal-Baptist and North Alabama. Given that much of these preseason rankings depends on end of season rankings from last year, setting prior rankings for Cal-Bapist and North Alabama required imputing missing values. I looked at the correlation betwen my preseason offensive and defensive coefficients with T-Rank adjusted offensive and defensive efficiencies. Perhaps I’m beating a dead horese here is reminding the reader that my own coefficients are not measures of efficiency, and one might wonder then why I’d use adjusted efficieny margins to impute preseason rankings for these schools. Overall, even though my coefficients and Bart’s rankings have different interpretations, there is a high correlation, and as such, this gives me a quick and dirty way to impute the preseason ranking for 2 of the 353 D1 teams. Using this imputation yields the following results\n## rank team off_coeff def_coeff yusag_coeff ## 1 338 North Ala. -8.554625 -3.560665 -12.11529 ## 2 346 California Baptist -8.554573 -5.105342 -13.65992  In-Season Updating Let \\(\\alpha_{prior}, \\delta_{prior}\\) and \\(\\gamma_{prior}\\) denote a team’s prior season coefficients. We’ll also obtain coeffient estimates from the current season’s games that have already been played, using least squares regression model explained above. I’ll note that in fitting this in-season model, I actually use weights to add a little bit of recency bias. That is, games that have been played are weighted more heavily. Suppose Team A and Team B played a game. It was the \\(i^{th}\\) game of the season for Team A and and the \\(j^{th}\\) game of the season for Team B. Furthermore, suppose that Team A has played \\(n_a\\) games to date and Team B has played \\(n_b\\) games to date. We define the relative recency of a game, \\(r\\) as follows. \\[ r = \\frac{1}{2}\\biggl(\\frac{i}{n_a} + \\frac{j}{n_b}\\biggr) \\] Finally, the games weight in the model is given by \\[ w = \\frac{1}{1 + 0.5^{5r}e^{-r}} \\] This bias really only downweights early season games when the majority of the season has already been played.\nOk so now that we have coefficient estimates for each team prior to the season and estimates from the current season’s worth of data what do we do? Part of the reason the preseason ratings of interesting is that estimates of team coefficients are extremely noisy early in the season. To get around this, we can take a weighted average of a team’s in-season coefficients and preseason coefficients. Suppose a team has \\(n\\) games on it’s schedule, and it’s most recent game played was the \\(k^{th}\\) game on the schedule. Then we have \\[ w = \\min\\biggl(\\frac{2k}{n}, 1\\biggr) \\] \\[ \\gamma_{team} = w\\gamma_{in\\_season} + (1-w)\\gamma_{pre\\_season} \\]\nNote that we do the same as above for \\(\\alpha_{team}\\) and \\(\\delta_{team}\\). Preseason weights fall out completely once a team completes \\(\\frac{1}{2}\\) of it’s schedule, as the halfway point is roughly the point in the season by which coefficient estimates begin to stablilize. One might wonder why not take a full Bayesian approach to get posterior distributions for model coefficients. I’m hesitant to take a full Bayesian approach is that the I’m fairly confident my uncertainty estimates are underestimates, meaning these preseason priors would be too informative. I think that after spending this season evaluating the current framework, I’d feel more comfortable setting weaker priors around similarly obtained point estimates to establish a Bayesian framwork. That’s definitely the direction this project is headed but I have to make sure I wouldn’t be setting terrible priors before making such a switch.\nFor full 1-353 rankings, click here. Code for this model will be updating shortly here\n  Acknowledgements I can’t finish this post without thanking Bart Torvik one final time. Bart provided me with a lot of his proprietary data over the summer and answered many many questions I had in setting priors. Be sure to check out his site if you haven’t yet!\n ","date":1540080000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540080000,"objectID":"f35f18b80307fb4ecd268a747401e24d","permalink":"https://lukebenz.com/post/hoops_methodology/","publishdate":"2018-10-21T00:00:00Z","relpermalink":"/post/hoops_methodology/","section":"post","summary":"Introduction For the past two years, I’ve been maintaining a men’s college basketball prediction model that I first built for the Yale Undergraduate Sports Analytics Group (YUSAG) during my sophomore year of college. The model has done objectively quite well over the past two seasons. It correctly predicted last year’s National Champion, Villanova, and accurately predicted North Carolina and Gonzaga as the most likely finalists in the 2017 title game.","tags":null,"title":"NCAA Hoops Model Methodology","type":"post"},{"authors":null,"categories":null,"content":" NIST Homegeneity Assessor User\u0026rsquo;s Manual (Summer 2018) Paper Launch and Demonstration of the NIST Homogeneity Assessor (Summer 2018) Slides Combining Results in Collaborative Studies when Reported Uncertainties are Unreliable (Summer 2017) Slides  ","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"42f5ff00dfa2c804c03b39dca6ab4413","permalink":"https://lukebenz.com/project/nist/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/project/nist/","section":"project","summary":"Presentations from NIST Summer Undergraduate Research Fellowship","tags":["NIST"],"title":"NIST","type":"project"},{"authors":null,"categories":null,"content":" Former NFL head coach, and current Arizona State coach, Herm Edwards once famously said, “you play to win the game.”. Every once in a blue mood, Edwards’ logic is actually false, and sometimes teams don’t play to win–because they are incentivized NOT to win. At the 2012 Summer Olypmics, for example, several badmitton teams intentionally lost in hopes of securing a more favorable draw through the knockout phases of the tournament.\nThere is speculation that we might see more of this when Belgium and England square off in the final match of Group G at the 2018 FIFA World Cup. Both squads come into the match with 2 wins apiece, having each already secured slots in the knockout round. All that remains to be determined is who will win the group, and who will finish as runner-up. Either squad would win the group if victorious, and since England and Belgium are tied on points, goal differential, and goals forced, meaning a draw would result in the group winner being decided via FIFA Fair Play. This means that England would need to get at least 2 more yellow cards than Belgium to have any chance of advancing via a draw. Prior to Group G and H finishing, here’s how the Knockout Round bracket is looking. The top half of the bracket looks absolutely stacked compared to the bottom half of the bracket. My World Cup model produces net ratings and world rankings for each country, allowing us to examine the disparity between the two halfs of the bracket\nTop Half Rankings\n Brazil 2.97 (1) France 2.92 (2) Portugal 2.63 (10) Uruguay 2.59 (12) Argentina 2.50 (14) Mexico 2.12 (25)  Bottom Half Rankings\n Spain 2.72 (6) Croatia 2.71 (7) Denmark 2.62 (11) Sweden 2.57 (13) Switzerland 2.33 (19) Russia 1.96 (35)  Are these groups really that different in talent? The average rating in the upper half of the bracket is 2.62, while the average team in the lower half of the bracket is 2.48 . Among teams to qualify for the Knockout Round, we can simulate the average talent disparity between the top half of the bracket, when the Group G winner will go, and the lower half of the bracket, where the Group G runner-up will go.\nIn the histogram displaying talent disparities from 100,000 simulated knockout brackets based on pre-tournament probabilities to advance, we see that the disparity based on current ratings isn’t that big. Perhaps the reason that we think the disparity is larger than it actually is that that big-name teams in the top-half of the bracket, namely Argentina, are worse than expected pre-tournament, while several teams in the bottom half, like Croatia, Sweden, and Switzerland, have all improved in rating since the beginning of the tournament. Irregardless, there is truth in the fact that the top half of the knockout break is stronger on average than the bottom half of the bracket. Let’s see how England and Belgium fair based on which half of the bracket they are in to see if losing in order to finish second in Group G really is better.\n## finish Qtrs Semis Final Champ ## 1 eng_first 0.639 0.294 0.137 0.070 ## 2 eng_second 0.590 0.330 0.173 0.074 ## 3 belg_first 0.660 0.339 0.178 0.089 ## 4 belg_second 0.657 0.375 0.208 0.117 Using Monte Carlo, I simulated the knockout round 1000 times with each Belgium winning the group and 1000 times with England winning the group. Not suprisingly, both teams had better round-by-round advancement probabilities across the board, with the exception of the quarterfinals, when finishing as group runner up.\nConditioning on Colombia There is however, an additional interesting factor to consider. While “G” comes before “H”, FIFA has decided to schedule the final round of Group H matches on Thursday morning while scheduling the Group G matches on Thursday afternoon. This means that both England and Belgium will know who their opponets in the round of 16 would be based on the early morning results from Group H. More specifically, England and Belgium will know which half of the draw Colombia is on. Colombia is the 5th ranked team in my model, with a rating of 2.73 , and would be a much more difficult matchup than either Japan or Senegal, the other two potential Group H teams Colombia or Belgium would face. The possibility of facing Colombia is exactly why the quarterfinal advantage seems to disappear. Would the possibility of facing Columbia as Group H winners make it worth winning Group G instead? We can simulate the knockout round 1000 times with Colombia winning Group H (sent to bottom-half), finishing runners up (sent to top-half), or missing the knockout round all together.\nWe see based on the chart above that matching Colombia’s result if they progress is favorable in the long run to simply trying to finish group runner’s up. Simply avoiding Colombia in the first round can be worth about 3-5% in Belgium and England’s chances of winning the World Cup, with both countries best odds coming when they land in the lower half of the bracket AND avoid Colombia. So overall, perhaps the biggest advantage for England and Belgium is knowing who their opponents would be with 100% certainty prior to their own game. And do be surprised if things get a little crazy with one team trying to ensure they lose, especially if Colombia fails to win Group H. Sorry, Herm – you don’t always “play to win the game”. And maybe–just maybe–it’ll be a whole lot more fun.\n Acknowledgements I’d like to thank Gregory Matthews for giving me the idea to write this article.\n ","date":1530057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530057600,"objectID":"c54206ef8af03fcec3db68d262a4737a","permalink":"https://lukebenz.com/post/eng_bel/","publishdate":"2018-06-27T00:00:00Z","relpermalink":"/post/eng_bel/","section":"post","summary":"Former NFL head coach, and current Arizona State coach, Herm Edwards once famously said, “you play to win the game.”. Every once in a blue mood, Edwards’ logic is actually false, and sometimes teams don’t play to win–because they are incentivized NOT to win. At the 2012 Summer Olypmics, for example, several badmitton teams intentionally lost in hopes of securing a more favorable draw through the knockout phases of the tournament.","tags":["World Cup","Soccer"],"title":"You Play to…Lose the Game?","type":"post"},{"authors":null,"categories":null,"content":" With the second round of group stage matches complete at the 2018 FIFA World Cup, knockout round qualification is becoming clearer. Several teams have already clinched their spots past the group stage, with a few more near locks to do so on the final match day. There are, however, still a few groups with something left to play for, ensuring dramatic matches during this next week. After running the latest batch of Monte Carlo simulations with my World Cup model to estimate each country’s chances of advancing to the knockout round, I noticed a few neat probability quirks that reveal a lot about which groups are sure to provide viewers with the most exciting final match day.\nGroup F After Toni Kroos’ last gasp winner over Sweden, it’s not exactly groundbreaking to suggest that Group F, comprised of Mexico, Germany, Sweden, and South Korea, will offer one of most exciting endings of any group. All four teams are still alive heading into the final round of matches, meaning everyone’s best squad will be on display. Yet, that’s not the primary reason this group caught my eye. Rather, Group F really caught my eye when I looked at the group standings after 10,000 simulations.\n## country group expected_pts first_in_group second_in_group r16 ## 1 Germany F 5.48 0.2164 0.6196 0.8360 ## 2 Mexico F 7.24 0.6055 0.1071 0.7126 ## 3 Sweden F 4.47 0.1781 0.2541 0.4322 ## 4 Korea Republic F 0.36 0.0000 0.0192 0.0192 Interestingly, despite leading the group with 6 points, Mexico does not possess the best chance to advance, and frankly, it’s not really that close. According to my model, Germany is about 13% more likely to move on than Mexico. FiveThirtyEight founder Nate Silver noted the same quirk on Twitter. What makes this really interesting, is that Mexico is nearly 3 times as likely as Germany to win thr group, and get roughly 1.7 more points than Germany on average. How is this possible? It all boils down to conditional probability. First, recall the law of total probability. If \\(A\\) is an event, and \\(B_1, ..., B_n\\) are a disjoint parition of the of the sample space, then \\[ \\mathbb{P}(A) = \\sum_{i = 1}^n \\mathbb{P}(A|B_i) \\times \\mathbb{P}(B_i) \\] In the contest of the World Cup, we can think of \\(A\\) as being the event that Mexico advances, and \\(B_1, B_2\\), and \\(B_3\\) being the events that Mexico wins, ties, or loses its final match against Sweden. Then, we have \\[ \\mathbb{P}(\\text{Mexico Advances}) = \\mathbb{P}(\\text{Mexico Advances }|\\text{ win}) \\times \\mathbb{P}(\\text{win}) + \\mathbb{P}(\\text{Mexico Advances }|\\text{ tie}) \\times \\mathbb{P}(\\text{tie}) + \\mathbb{P}(\\text{Mexico Advances }|\\text{ loss}) \\times \\mathbb{P}(\\text{loss}) \\]\nMexico is guarteed to win the group with a win or a tie against Sweeden, so \\(\\mathbb{P}(\\text{Mexico Advances }|\\text{ win}) = \\mathbb{P}(\\text{Mexico Advances }|\\text{ tie}) = 1\\). With a loss however, Mexico’s position is much more precarious. Full scernarious are outlined here, and Mexico can still advance with a loss, but accoring to my simulations, \\(\\mathbb{P}(\\text{Mexico Advances }|\\text{ loss})\\) is only about 25%. Conditional on the fact that Mexico loses, they would lose any head to head tiebreaker Sweden, meaning a Germany win over South Korea would almost certainly eliminate El Tri. As for Germany’s favorable odds, a simple look at the expected goal distirbution for the final two matches expain why my model suggests Mexico isn’t as safe as one might’ve thought.\n Group H The other interesting group from a probability standpoint is Group H, comprised of Senegal, Poland, Japan, and Colombia. While Poland has been elimanted from the World Cup, the other three squads have a good will fight on the final match day for two spots in the knockout round. Here’s how the simulations see the group shaking out.\n## country group expected_pts first_in_group second_in_group r16 ## 1 Senegal H 5.94 0.5168 0.2633 0.7801 ## 2 Japan H 4.71 0.2340 0.2608 0.4948 ## 3 Poland H 3.36 0.1338 0.2807 0.4145 ## 4 Colombia H 2.91 0.1154 0.1952 0.3106 We see two things about this that are noteworthy.\nJapan, Senegal, and Colombia are all each more likely to advance than not despite the fact that one of them will not advance. All three of the those countries are essentially a 2/3 chance of advancing.  At first, 1. might seem somewhat paradoxical, but actually it’s quite reasonable. After all \\[ \\sum_{teams} \\mathbb{P}(\\text{team advances}) = 2 \\] as there are 2 spots in the knockout round for each group. Given that Poland has already been eliminated, we must divide that 200% of probability amongst 3 teams somehow, and doing so in a relatively even manner yields this neat result. Micah McCurdy has a good explanation on this phenomon in general. Perhaps even more interesting is the fact that the three remaining countries’ chances don’t deviate significantly from a true random draw, in which each country’s chances would be exactly 2/3. Any time you have random or near random events in sports, it’s almost always exciting (this is why we find March Madness so appealing, for instance), meaning that Group H’s final matchday will be must-see TV. Here’s how my model sees the final Group H matches.3\n ","date":1529798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529798400,"objectID":"74506e4d423d152b3ebc265c16f462ad","permalink":"https://lukebenz.com/post/wc_prob_quirks/","publishdate":"2018-06-24T00:00:00Z","relpermalink":"/post/wc_prob_quirks/","section":"post","summary":"With the second round of group stage matches complete at the 2018 FIFA World Cup, knockout round qualification is becoming clearer. Several teams have already clinched their spots past the group stage, with a few more near locks to do so on the final match day. There are, however, still a few groups with something left to play for, ensuring dramatic matches during this next week. After running the latest batch of Monte Carlo simulations with my World Cup model to estimate each country’s chances of advancing to the knockout round, I noticed a few neat probability quirks that reveal a lot about which groups are sure to provide viewers with the most exciting final match day.","tags":["World Cup","Soccer"],"title":"World Cup Probability Quirks","type":"post"},{"authors":null,"categories":null,"content":" Introduction With the 2018 FIFA World Cup nearly upon us, we set out to build a model to predict game outcomes and estimate coutries chances of reaching various rounds of the tournament. Ranking systems for various sports, including NCAA Men’s Basketball, NCAA Football, and NBA, have been the basis of several of our projects in the past. With the exception of rankings using ELO, all of our past ranking systems have made use of linear regression in one form or another. Simply, those models took on something similar to the following form \\[ Y = \\beta_0 + \\beta_{team} X_{team} + \\beta_{opp} X_{opp} + \\beta_{loc} X_{loc} + \\epsilon \\] where \\(X_{team, i}, X_{opp, i}\\), and \\(X_{loc, i}\\) are indicator vectors for the \\(i^{th}\\) game’s team, opponent, and location (Home, Away, Neutral) from the perspective of team, and \\(Y_i\\) is game’s the score-differential. The key assumptions for this model are that game outcomes are independent of one another, and that our error \\(\\epsilon \\sim N(0, \\sigma^2)\\).\n First Attempt Before going into detail on the model we ultimated settled on, let’s first examine what didn’t work–and more importantly why. Given our prior experience using linear regression to predict score differential in several different sporting events, it seemed natural to extend the notion to international soccer. In fact, our initial attempt seemed quite reasonable. The basic idea was as follows:\n Use linear regression with covariates team, opponent, and location to predict goal_diff (a game’s goal differential). Use a multinomial logistic regression model with input pred_goal_diff to estimate probabilities of win, loss, and tie. Our rankings indicated that Germany, Brazil, and Spain were the top 3 teams, entirely plausible our eyes (as casual soccer fans).  In writing Monte Carlo simulations to estimate round-by-round probabilities of advacing, we began to notice a potential fault in our model. While it was easy enough to simulate game outcomes and award points (3 for win, 1 for tie, 0 for loss) given our estimated win, loss, and tie probabilites for each of the group stage games, breaking ties in the group standings to determine which two teams would advance to the knockout round presented more of a challenge. If two or more teams are tied on points after a round robin within the group, the first tie-breaker is net goal differtial, a country’s goals scored - goals allowed in the 3 group stage games. Our initial thought was to simply flip a coin to break ties, but this underestimates the probabiity that better teams advance past the group stage. Consider the following hypothethical scenario in group B:\n    country   sim_points    1   Spain  9    2   Portugal  4    3   Morocco  4    4   Iran  0    Simply flipping a coin to determine whether Portugal or Morocco would advance in the above case almost certianly underestimates the chances that Portugal, the superior of the two, would have a larger goal differential than Morocco. So, was there a better way to account for goal differntial? Recall, goal_diff was the response variable of our linear regression. A nice result of simple linear regression is that for game \\(i\\), we have \\(\\widehat Y_i\\) normally distributed. Since \\(\\widehat Y_i = \\widehat \\beta_0 + \\widehat\\beta X_i\\) and each \\(\\widehat \\beta_i \\sim N(\\beta_i, \\sigma_i^2)\\), \\[\\widehat Y_j \\sim N(\\beta_0 + \\beta X_j, \\sum_i \\sigma_i^2)\\] Approximating such a distribution using prediction intervals for goal_diff, perhaps we could form net goal differential distributions for each team in group play and randomly draw from those distrubutions in the case of a tie in the group standings. Things quickly became not well-defined when trying to draw from \\(Y \\sim N(\\mu, \\sigma^2) | Y \\geq 1\\) (in case of loss, \\(Y \\leq -1\\)). Moreover, in the case of a tie, we’d be setting \\(Y = 0\\) in our simulation, yet under the normal distribution, \\(P(Y = 0) = 0\\) (in fact the probability \\(Y = c\\) exactly is 0 any fixed constant \\(c\\)). By this point, we’d realized we were in trouble, as drawing from this continuous distribution for a discrete random variable didn’t make a lot of sense. Back to the drawing board.\n Taking a Step Back At this stage, there are two questions to consider. The first, is why didn’t a linear model, which had worked well for us in the case of basketball and football, work well in the case of soccer? Furthermore, we wondered, if not a linear model, what type of model would work best? The answer to both of these questions is best seen by looking at histograms of points/goals scored in soccer games vs. basketball games.\nBased on the plots above, we see that the distribution of basketball scores looks like a bell curve, while the distribution of soccer scores does not. Rather, the distribution of soccer scores looks to be more like a Poisson distribution. Recall that the probability mass function (PMF) of the possion distribution with parameter \\(\\lambda\\) is by \\[ P(X = k) = \\frac{e^{-\\lambda}\\lambda^k}{x!} \\textrm{ for } x = 0, 1, 2, ... \\]\nAdditionally, if \\(X \\sim Pois(\\lambda)\\), \\(\\mathbb{E}(X) = \\lambda\\). As \\(\\lambda\\) gets large, Poisson distributions become more and more like Guassians, hence the ability for sports with larger average scores (i.e. basketball) to be better modeled with a Normal Model than sports with lower scores (i.e. soccer, hockey). Since the difference of i.i.d. normal random variables is also normal, linear regression is perfectly fine for modeling score_diff is basketball. However, the difference of two i.i.d. poisson random variables is not normal nor poisson. Rather, the difference of two poisson random variables follows the skellam distribution. Thus, it seems like our best bet here is to use poisson regression for our model. In fact, several studies have shown that poisson regression is good for modeling soccer 1 2 3 4.\n Building the Model The data, available on Kaggle, covers over 39,000 international soccer matches dating back to 1872. For the purpose of this model, we have chosen to use data for games played after January 1, 2014. Many major tournaments in soccer, the World Cup included, occur on a four year cycle, so using the last 4 years worth of data seemed natural.\nDaniel Sheehan has written a fantastic blog post on using poisson regression to predict the outcomes of soccer games, and our model is based off of his work (he provides lots of examples in both R and Python, and we’d highly recommend reading it!).\nWe began by duplicating the data set and transforming one copy to be from the perspective of the opponent. For example, if we had the vector in the \u0026lt; team = \"Germany\", opponent = \"Brazil\", location = \"N\", team_score = 7, opp_score = 1 \u0026gt;, we’d also add to our data set the vector \u0026lt;team = \"Brazil\", opponent = \"Germany\", location = \"N\", team_score = 1, opp_score = 7 \u0026gt;. What we eventually end up predicting is team_score as a function of team, opponent, and location.\nBefore actually building the model, there were one more things that we considered, namely match_weight, how much weight we should give a particular game. There were two factors on which the model weights were set: time since the was played, and the type of match being played. We broke matches in our data set into four types (derived from the official FIFA rankings formula):\n Friendlies and other matches (Base Weight \\(\\alpha_i = 1\\)) Qualification matches for World Cup and continental championships (Base Weight = \\(\\alpha_i = 3\\)) Confederations Cup and continental championships (Base Weight = \\(\\alpha_i = 5\\)) World Cup Matches (Base Weight = \\(\\alpha_i= 8\\))  Letting \\(\\delta_i\\) represent the date on which game \\(i\\) was played and let \\(\\delta_t\\) be today’s date (i.e. the date we choose to fit/re-fit the model). Finally, take \\(\\delta\\star = \\max_{i} (\\delta_t - \\delta_i)\\). Then, the match_weight, \\(w_i\\) of match \\(i\\) is given by \\[ w_i = \\alpha_i \\times e^{- \\frac{\\delta_t - \\delta_i}{\\delta\\star}} \\] We see above that the 2014 World Cup and the 2016 Euro Cup are among the most heavily weighted games, as we would hope. Now the call to the model is as follows:\nglm.futbol \u0026lt;- glm(goals ~ team + opponent + location, family = \u0026quot;poisson\u0026quot;, data = y, weights = match_weight) The model gives coefficients for each country both as levels of the team and opponent factors. Since the model output predictions can be taken as the average team_score for a given team against a given opponent at a given location, we can view the country specific coefficients as offense and defensive components of a power rating. The interpretation of such coefficients is less intutive than in the case of linear regression, in which coefficients signfy points better than an average team, but you can think of them as more similar to logistic regression coefficients. Higher offensive coefficients indicate a team is likely to score more goals on average while low (more negative) defensive coefficients indicate a team is likely to conceed fewer goals on average.\n## team offense defense net_rating rank ## 77 Germany 1.707366 -1.373929 3.081295 1 ## 72 France 1.581282 -1.307218 2.888500 2 ## 29 Brazil 1.727649 -1.097520 2.825169 3 ## 181 Spain 1.639751 -1.116924 2.756675 4 ## 9 Argentina 1.318170 -1.438423 2.756593 5 ## 45 Colombia 1.456873 -1.285449 2.742322 6 ## 20 Belgium 1.565169 -1.140337 2.705506 7 ## 140 Netherlands 1.597657 -1.065459 2.663115 8 ## 158 Portugal 1.442856 -1.200933 2.643789 9 ## 64 England 1.269063 -1.281223 2.550285 10 Offensively, the top teams by our model, are Brazil, Germany and Spain, while Argentina, Germany, and England posses the best defenses.\n Sample Match Prediction To see how this model works in more detail, let’s walk through how we predict the outcome of a single match. We’ll use the marquee Spain-Portugal fixture from Group B as our case study. The model output for the vector \u0026lt;team = \"Spain\", opponent = \"Portugal\", location = \"N\" \u0026gt; is 1.37, while the model output for the vector \u0026lt;team = \"Portugal\", opponent = \"Spain\", location = \"N\" \u0026gt; is 1.21 . This signifies that on average, we expect Spain to score 1.37 goals and expect Portugal to score 1.21 goals. There is much more information encoded in these two numbers however. Let \\(X_s\\) be the random variable denoting the number of goals Spain score and let \\(X_p\\) denote the number of goals that Portugal scores. Then, we have that \\(X_s \\sim Pois(\\lambda_s = 1.37)\\) and \\(X_p \\sim Pois(\\lambda_p = 1.21)\\), and from these distributions, we can get a lot of neat stuff. First, we can look at the joint distribution of goals scored. Rows indicate the number of goals Spain scores while columns correspond to the number of goals Portugal scores.\n    0   1   2   3    0  0.0758  0.0917  0.0555  0.0224    1  0.1038  0.1256  0.0760  0.0307    2  0.0711  0.0860  0.0521  0.0210    3  0.0325  0.0393  0.0238  0.0096    Perhaps unsuprisingly, the most likely outcome is a 1-1 draw, but there is still about an 87% chance we see a different outcome. Summing the diagonal entries of this matrix (extended out beyond 3 goals–let’s assume it’s neither team will score more than 10 goals) gives the probability that that Iberian neighbors end in a stalemate, while summing the entries above the diagonal or below the diagonal yield Portugal or Spain’s chances of winning, respectively. Overall, we estimate that Spain has about a 41% chance to win, Portugal has about a 33% chance to win, and there is a 26% chance the two teams draw.\n Simulating the World Cup Now that we have the ability predict any game, we can run some Monte Carlo simulations to estimate the probability of each time winning the World Cup. We run 10,000 iterations of the following simulation steps:\nSimulate each group game by drawing the number of goals scored by each team from their respective poisson distributions. Advance the top 2 teams in each group by points, and in the case of ties, use goal differential, goals forced, and goals allowed (in that order) as tiebreakers. Simulate knockout round games as in step 1. If there is a tie, flip a coin to determine who wins the simulated penalty shooutout (assuming that teams convert penalties at similar rates, this is not a decent approximation 5). Repeat step 4 until there is a champion  Our simulations indicate that despite being in the so called “group of death”, defending champion Germany is most likely to win the World Cup, with a roughly 16% chance to hoist the crown. Brazil (11%), Frace (9%), Spain (8%), and the trio of Argentina, Belgium and Columbia (6% each) follow closely behind. A full list of World Cup odds, as well as the code used in this project can be found on GitHub.\n Limitations A key assumption of the poisson distribution is that the rate parameter \\(\\lambda\\) does not depend on time. That is, in using this model, we are assuming that the rate of goals is equal during each minute of the match. However, this is not true in practice, and several sources extend their framework to bivariate poisson regression 6 7 8 9. Other limitations include the relatively small number of important matches in international soccer. While we examine on a 4 year basis, there may only be 15-20 matches per team of the highest importance, making prediction dificult even with our best effort to correct for difference between matches on the basis of time and relative importance.\n Acknowledgements We’d like to thank Kostas Pelechrinis and Michael Lopez for offering suggestions regarding the switch from linear to poisson regression, as well as providing example papers modeling soccer outcomes using poisson regressions. Additionally, we’d like to thank Edward Egros, who mentioned the data set used in this project during his April visit to Yale University.\n  https://www.jstor.org/stable/4128211?seq=1#page_scan_tab_contents↩︎\n https://epub.ub.uni-muenchen.de/29028/1/TR_EM2016.pdf↩︎\n http://www2.stat-athens.aueb.gr/~jbn/tr/TR60_soccer.ps↩︎\n http://www2.stat-athens.aueb.gr/~karlis/Bivariate%20Poisson%20Regression.pdf↩︎\n https://fivethirtyeight.com/features/a-chart-for-predicting-penalty-shootout-odds-in-real-time/↩︎\n https://www.jstor.org/stable/4128211?seq=1#page_scan_tab_contents↩︎\n https://epub.ub.uni-muenchen.de/29028/1/TR_EM2016.pdf↩︎\n http://www2.stat-athens.aueb.gr/~jbn/tr/TR60_soccer.ps↩︎\n http://www2.stat-athens.aueb.gr/~karlis/Bivariate%20Poisson%20Regression.pdf↩︎\n   ","date":1528588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528588800,"objectID":"ef1e2d6c0a52f6d35cac8cbbd91b1052","permalink":"https://lukebenz.com/post/wc_model_methodology/blogpost/","publishdate":"2018-06-10T00:00:00Z","relpermalink":"/post/wc_model_methodology/blogpost/","section":"post","summary":"Introduction With the 2018 FIFA World Cup nearly upon us, we set out to build a model to predict game outcomes and estimate coutries chances of reaching various rounds of the tournament. Ranking systems for various sports, including NCAA Men’s Basketball, NCAA Football, and NBA, have been the basis of several of our projects in the past. With the exception of rankings using ELO, all of our past ranking systems have made use of linear regression in one form or another.","tags":["World Cup","Soccer"],"title":"World Cup Methodology","type":"post"},{"authors":null,"categories":null,"content":" Featured Solutions  7/27/18 Riddler Classic 8/18/17 Riddler Classic  Blog Posts  Transitive National Champions  Code solutions to several riddlers can be found here.\n","date":1526774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526774400,"objectID":"ecc5851d4279cb526037beba2cb02bca","permalink":"https://lukebenz.com/project/fivethirtyeight_riddlers/","publishdate":"2018-05-20T00:00:00Z","relpermalink":"/project/fivethirtyeight_riddlers/","section":"project","summary":"A list of solutions to FiveThirtyEight Riddlers","tags":null,"title":"FiveThirtyEight Riddlers","type":"project"},{"authors":["Luke Benz","Margret Wrensch","Joellen Schildkraut","Melissa Bondy","Joshua Warren","Joseph Wiemels","Elizabeth Claus"],"categories":null,"content":"","date":1505260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505260800,"objectID":"dc7a562b31b77d3e07f19d90ef18364a","permalink":"https://lukebenz.com/publication/qol_meningioma/","publishdate":"2017-09-13T00:00:00Z","relpermalink":"/publication/qol_meningioma/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Quality of life after surgery for intracranial meningioma","type":"publication"}]